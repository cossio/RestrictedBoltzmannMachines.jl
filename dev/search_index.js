var documenterSearchIndex = {"docs":
[{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/dReLU.jl\"","category":"page"},{"location":"literate/layers/dReLU/#dReLU-layer","page":"dReLU","title":"dReLU layer","text":"","category":"section"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"In this example we look at what the dReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"First load some packages.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"import RestrictedBoltzmannMachines as RBMs\nimport Makie\nimport CairoMakie\nusing Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Now initialize our dReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Œ∏ps = [-3.0; 3.0]\nŒ∏ns = [-3.0; 3.0]\nŒ≥ps = [0.5; 1.0]\nŒ≥ns = [0.5; 1.0]\nlayer = RBMs.dReLU(\n    [Œ∏p for Œ∏p in Œ∏ps, Œ∏n in Œ∏ns, Œ≥p in Œ≥ps, Œ≥n in Œ≥ns],\n    [Œ∏n for Œ∏p in Œ∏ps, Œ∏n in Œ∏ns, Œ≥p in Œ≥ps, Œ≥n in Œ≥ns],\n    [Œ≥p for Œ∏p in Œ∏ps, Œ∏n in Œ∏ns, Œ≥p in Œ≥ps, Œ≥n in Œ≥ns],\n    [Œ≥n for Œ∏p in Œ∏ps, Œ∏n in Œ∏ns, Œ≥p in Œ≥ps, Œ≥n in Œ≥ns]\n)\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"fig = Makie.Figure(resolution=(1000, 700))\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1,1,1,1,100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iŒ∏p, Œ∏p) in enumerate(Œ∏ps), (iŒ∏n, Œ∏n) in enumerate(Œ∏ns)\n    ax = Makie.Axis(fig[iŒ∏p,iŒ∏n], title=\"Œ∏p=$Œ∏p, Œ∏n=$Œ∏n\", xlabel=\"h\", ylabel=\"P(h)\")\n    for (iŒ≥p, Œ≥p) in enumerate(Œ≥ps), (iŒ≥n, Œ≥n) in enumerate(Œ≥ns)\n        Makie.hist!(ax, data[iŒ∏p, iŒ∏n, iŒ≥p, iŒ≥n, :], normalization=:pdf, bins=30, label=\"Œ≥p=$Œ≥p, Œ≥n=$Œ≥n\")\n        Makie.lines!(ax, xs[iŒ∏p, iŒ∏n, iŒ≥p, iŒ≥n, :], ps[iŒ∏p, iŒ∏n, iŒ≥p, iŒ≥n, :], linewidth=2)\n    end\n    if iŒ∏p == iŒ∏n == 1\n        Makie.axislegend(ax)\n    end\nend\nfig","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/performance/mkl.jl\"","category":"page"},{"location":"literate/performance/mkl/#MKL-vs.-OpenBLAS","page":"MKL","title":"MKL vs. OpenBLAS","text":"","category":"section"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"With an Intel CPU, MKL is generally faster than OpenBLAS. Let's do a quick comparison.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"import MLDatasets\nimport Makie\nimport CairoMakie\nusing ValueHistories: MVHistory","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Load MNIST","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nnothing #hide","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Make  sure we are using OpenBLAS first:","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"using LinearAlgebra\nLinearAlgebra.__init__() # use OpenBLAS\nBLAS.get_config()","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Number of BLAS threads:","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"BLAS.get_num_threads()","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Train RBM using OpenBLAS.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"import RestrictedBoltzmannMachines as RBMs\nrbm = RBMs.BinaryRBM(Float, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory_openblas = MVHistory()\ntime_0 = time()\nRBMs.cd!(\n    rbm, train_x; epochs=50, batchsize=128, steps=1,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history_openblas, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Now load MKL.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"using MKL\nMKL.__init__() # don't need this on a fresh Julia session\nBLAS.get_config()","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Number of BLAS threads:","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"BLAS.get_num_threads()","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"Now let's rerun the RBM training.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"RBMs.initialize!(rbm, train_x)\nhistory_mkl = MVHistory()\ntime_0 = time()\nRBMs.cd!(\n    rbm, train_x; epochs=50, batchsize=128, steps=1,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history_mkl, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"The epochs should be somewhat faster with MKL.","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"epoch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history_openblas, :t)..., label=\"OpenBLAS\")\nMakie.lines!(ax, get(history_mkl, :t)..., label=\"MKL\")\nMakie.ylims!(ax, low=0)\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"","category":"page"},{"location":"literate/performance/mkl/","page":"MKL","title":"MKL","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/performance/ad.jl\"","category":"page"},{"location":"literate/performance/ad/#Gradients-with-Zygote","page":"Zygote","title":"Gradients with Zygote","text":"","category":"section"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"It is possible to calculate gradients with Zygote. Let's compare performance to explicit gradients.","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"import MKL\nimport MLDatasets\nimport Makie\nimport CairoMakie\nimport RestrictedBoltzmannMachines as RBMs\nusing ValueHistories: MVHistory\nusing RestrictedBoltzmannMachines: BinaryRBM, initialize!, cd!, cdad!\nnothing #hide","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Setup","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Float = Float32\nepochs = 100\nbatchsize = 128\nnothing #hide","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Load MNIST","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nnothing #hide","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Train using explicit gradients","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"rbm_‚àÇs = BinaryRBM(Float, (28,28), 128)\n@time cd!(rbm_‚àÇs, train_x) # warm-up run so as to not consider pre-compilation times\ninitialize!(rbm_‚àÇs, train_x)\nhistory_‚àÇs = MVHistory()\ntime_0 = time()\n@time cd!(\n    rbm_‚àÇs, train_x; epochs, batchsize,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history_‚àÇs, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Train using Zygote gradients","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"rbm_ad = BinaryRBM(Float, (28,28), 128)\n@time cdad!(rbm_ad, train_x) # warm-up run so as to not consider pre-compilation times\ninitialize!(rbm_ad, train_x)\nhistory_ad = MVHistory()\ntime_0 = time()\n@time cdad!(\n    rbm_ad, train_x; epochs, batchsize,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history_ad, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"Compare timings","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"batch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history_‚àÇs, :t)..., label=\"manual\")\nMakie.lines!(ax, get(history_ad, :t)..., label=\"zygote\")\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"","category":"page"},{"location":"literate/performance/ad/","page":"Zygote","title":"Zygote","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/moment_match.jl\"","category":"page"},{"location":"literate/moment_match/#Moment-matching-conditions","page":"Moment-matching","title":"Moment-matching conditions","text":"","category":"section"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"The stationarity conditions for ML learning of the RBM imply certain moment-matching conditions between the data and the RBM distribution. However, due to biased nature of the PCD approximation, these conditions might not hold exactly in practice.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"import Makie, CairoMakie\nimport MLDatasets\nimport Flux\nusing Statistics: mean, cor\nusing LinearAlgebra: norm\nusing RestrictedBoltzmannMachines: RBM, Binary, sample_from_inputs, free_energy, log_pseudolikelihood, training_epochs\nusing RestrictedBoltzmannMachines: sample_v_from_v, sample_h_from_v, initialize!, pcd!, minibatch_count, moving_average","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"load MNIST dataset","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"train_x = MLDatasets.MNIST(split=:train).features .> 0.5; # binarize\ntrain_y = MLDatasets.MNIST(split=:train).targets;\ntrain_x = train_x[:, :, train_y .== 0]; # only zeros for speed\nnothing #hide","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"floating type we will use","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Float = Float32","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"initialize RBM","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"nhidden = 64\nbatchsize = 64\nnupdates = 20000\nepochs = training_epochs(; nsamples = size(train_x, 3), nupdates, batchsize)\nrbm = RBM(Binary(Float,28,28), Binary(Float,nhidden), randn(Float,28,28,nhidden)/28)\ninitialize!(rbm, train_x);\nlpls = Float64[]\nFm = zeros(batchsize, epochs * minibatch_count(train_x; batchsize))\nFd = zeros(batchsize, epochs * minibatch_count(train_x; batchsize))\nt = lastepoch = 0\nfunction mycb(; epoch, vm, vd, kw...)\n    global lastepoch\n    global t += 1\n    Fm[:, t] .= free_energy(rbm, vm)\n    Fd[:, t] .= free_energy(rbm, vd)\n    if epoch > lastepoch\n        push!(lpls, mean(log_pseudolikelihood(rbm, train_x)))\n        lastepoch = epoch\n    end\nend\n@time pcd!(\n    rbm, train_x;\n    epochs, batchsize, callback=mycb, l2_weights=1e-4,\n    optim=Flux.ADAM(5e-4, (0.9, 0.999))\n);\nnothing #hide","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Plot log_pseudolikelihood during training","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.lines(lpls)","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Average energies of data and model fantasy particles used during training.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"fig = Makie.Figure()\nax = Makie.Axis(fig[1,1])\nMakie.lines!(ax, vec(mean(Fm; dims=1)), color=(:red, 0.25))\nMakie.lines!(ax, vec(mean(Fd; dims=1)), color=(:blue, 0.25))\nMakie.lines!(ax, moving_average(vec(mean(Fm; dims=1)), 20), color=:red, label=\"Fm\")\nMakie.lines!(ax, moving_average(vec(mean(Fd; dims=1)), 20), color=:blue, label=\"Fd\")\nMakie.axislegend(ax)\nfig","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Difference in average energies of data and model fantasy particles used during training.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"fig = Makie.Figure()\nax = Makie.Axis(fig[1,1])\nMakie.lines!(ax, vec(mean(Fm .- Fd; dims=1)), color=(:blue, 0.25))\nMakie.lines!(ax, moving_average(vec(mean(Fm .- Fd; dims=1)), 20), color=:red)\nfig","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Generate samples, in v-space and h-space.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"nsteps = 2000\nnsamples = 1000\nv_model = falses(28, 28, nsamples, nsteps);\nv_model[:,:,:,1] .= sample_from_inputs(rbm.visible, falses(28,28,nsamples));\nfor t in 2:nsteps\n    v_model[:, :, :, t] .= sample_v_from_v(rbm, v_model[:, :, :, t - 1])\nend\nh_data = sample_h_from_v(rbm, train_x);\nh_model = sample_h_from_v(rbm, v_model[:,:,:,end]);\n\nv_data_center = train_x .- mean(train_x; dims=3);\nh_data_center = h_data .- mean(h_data; dims=2);\nvh_data = reshape(v_data_center, 28*28, :) * h_data_center' / size(v_data_center, 3);\n\nv_model_center = v_model[:,:,:,end] .- mean(v_model[:,:,:,end]; dims=3);\nh_model_center = h_model .- mean(h_model; dims=2);\nvh_model = reshape(v_model_center, 28*28, :) * h_model_center' / size(v_model_center, 3);\nnothing #hide","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Average energy of generated and data points","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"fig = Makie.Figure()\nax = Makie.Axis(fig[1,1])\nMakie.hist!(ax, free_energy(rbm, train_x), color=:purple, label=\"data\", normalization=:pdf)\nMakie.hist!(ax, free_energy(rbm, v_model[:,:,:,end]), color=:orange, label=\"model\", normalization=:pdf)\nMakie.axislegend(ax)\nfig","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Plot moment-matching conditions","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"<v>data vs. <v>model","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.scatter(\n    vec(mean(train_x; dims=3)),\n    vec(mean(v_model[:,:,:,end]; dims=3))\n)\nMakie.xlims!(0,1)\nMakie.ylims!(0,1)\nMakie.current_figure()","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"<h>data vs. <h>model","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.scatter(\n    vec(mean(h_data; dims=2)),\n    vec(mean(h_model; dims=2)),\n)\nMakie.xlims!(0,1)\nMakie.ylims!(0,1)\nMakie.current_figure()","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"<vh>data vs. <vh>model","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.scatter(vec(vh_data), vec(vh_model))\nMakie.xlims!(0,1)\nMakie.ylims!(0,1)\nMakie.current_figure()","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Correlation","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"cor(vec(vh_data), vec(vh_model))","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Verify convergence of sampling","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.lines(vec(mean(free_energy(rbm, v_model[:,:,1:100,:]); dims=1)))","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Plot average sampled digit","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.heatmap(mean(v_model[:,:,:,end]; dims=3)[:,:,1])","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Plot average data digit","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.heatmap(mean(train_x; dims=3)[:,:,1])","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Difference","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Makie.heatmap(mean(v_model[:,:,:,end]; dims=3)[:,:,1] - mean(train_x; dims=3)[:,:,1])","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"Plot weights  of maximum intensity.","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"ùí´ = sortperm([norm(rbm.w[:,:,m]) for m in 1:nhidden]; rev=true);\n\nfig = Makie.Figure()\nfor i = 1:7\n    ax = Makie.Axis(fig[1,i], width=50, height=50)\n    Makie.heatmap!(ax, rbm.w[:, :, ùí´[i]])\n    Makie.hidedecorations!(ax)\n    Makie.hidespines!(ax)\nend\nMakie.resize_to_layout!(fig)\nfig","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"","category":"page"},{"location":"literate/moment_match/","page":"Moment-matching","title":"Moment-matching","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/Gaussian.jl\"","category":"page"},{"location":"literate/layers/Gaussian/#Gaussian-layer","page":"Gaussian","title":"Gaussian layer","text":"","category":"section"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"In the following example we look at what the Gaussian layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"First load some packages.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Now initialize our Gaussian layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Œ∏s = [-5; 5]\nŒ≥s = [1; 2]\nlayer = RBMs.Gaussian([Œ∏ for Œ∏ in Œ∏s, Œ≥ in Œ≥s], [Œ≥ for Œ∏ in Œ∏s, Œ≥ in Œ≥s])\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"fig = Figure(resolution=(700,500))\nax = Axis(fig[1,1])\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1, 1, 100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iŒ∏, Œ∏) in enumerate(Œ∏s), (iŒ≥, Œ≥) in enumerate(Œ≥s)\n    hist!(ax, data[iŒ∏, iŒ≥, :], normalization=:pdf, label=\"Œ∏=$Œ∏, Œ≥=$Œ≥\")\n    lines!(xs[iŒ∏, iŒ≥, :], ps[iŒ∏, iŒ≥, :], linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/metropolis.jl\"","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"import Makie\nimport CairoMakie\nusing Statistics: mean, std, var, cor\nusing Random: randn!, bitrand\nusing LogExpFunctions: logsumexp\nusing RestrictedBoltzmannMachines: BinaryRBM, energy, free_energy, metropolis!\n\nN = 5\nM = 2\nrbm = BinaryRBM(randn(N), randn(M), randn(N, M) / ‚àöN);\n\nŒ≤ = 0.5\nnsteps = 10000\nnchains = 100\nv = bitrand(N, nchains, nsteps)\nmetropolis!(v, rbm; Œ≤);\n\ncounts = Dict{BitVector, Int}()\nfor t in 1000:nsteps, n in 1:nchains\n    counts[v[:,n,t]] = get(counts, v[:,n,t], 0) + 1\nend\nfreqs = Dict(v => c / sum(values(counts)) for (v,c) in counts);\n\nùí± = [BitVector(digits(Bool, x; base=2, pad=N)) for x in 0:(2^N - 1)];\n‚Ñ± = free_energy.(Ref(rbm), ùí±);\n\nfig = Makie.Figure()\nax = Makie.Axis(fig[1,1], xlabel=\"empirical freqs.\", ylabel=\"log(p)\", xscale=log10, yscale=log10)\nMakie.scatter!(ax, [get(freqs, v, 0.0) for v in ùí±], exp.(-Œ≤ * ‚Ñ± .- logsumexp(-Œ≤ * ‚Ñ±)))\nMakie.scatter!(ax, [get(freqs, v, 0.0) for v in ùí±], exp.(-‚Ñ± .- logsumexp(-‚Ñ±)))\nMakie.abline!(ax, 0, 1, color=:red)\nfig","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"Correlation","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"cor([get(freqs, v, 0.0) for v in ùí±], exp.(-Œ≤ * ‚Ñ± .- logsumexp(-Œ≤ * ‚Ñ±)))","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"","category":"page"},{"location":"literate/metropolis/","page":"Metropolis","title":"Metropolis","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/center.jl\"","category":"page"},{"location":"literate/center/#MNIST","page":"No centering","title":"MNIST","text":"","category":"section"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Trained without centering.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"import Makie\nimport CairoMakie\nimport MLDatasets\nimport Flux\nimport RestrictedBoltzmannMachines as RBMs\nusing Statistics: mean, std, var\nusing Random: bitrand\nusing ValueHistories: MVHistory\nusing RestrictedBoltzmannMachines: visible, BinaryRBM, sample_from_inputs\nusing RestrictedBoltzmannMachines: initialize!, log_pseudolikelihood, pcd!, minibatch_count\nnothing #hide","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Useful function to plot grids of MNIST digits.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"\"\"\"\n    imggrid(A)\n\nGiven a four dimensional tensor `A` of size `(width, height, ncols, nrows)`\ncontaining `width x height` images in a grid of `nrows x ncols`, this returns\na matrix of size `(width * ncols, height * nrows)`, that can be plotted in a heatmap\nto display all images.\n\"\"\"\nimggrid(A::AbstractArray{<:Any,4}) =\n    reshape(permutedims(A, (1,3,2,4)), size(A,1)*size(A,3), size(A,2)*size(A,4))","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Load the MNIST dataset.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nnothing #hide","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Let's visualize some random digits.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"nrows, ncols = 10, 15\nfig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nidx = rand(1:size(train_x,3), nrows * ncols) # random indices of digits\ndigits = reshape(train_x[:,:,idx], 28, 28, ncols, nrows)\nMakie.image!(ax, imggrid(digits), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Initialize an RBM with 400 hidden units.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"rbm = initialize!(BinaryRBM(Float, (28,28), 400), train_x)\nbatchsize = 256\nbatchcount = minibatch_count(train_x; batchsize)\nepochs = 500\nhistory = MVHistory()\ntime_0 = time()\n@time pcd!(\n    rbm, train_x; epochs, batchsize, center=false,\n    callback = function(; epoch, batch_idx, _...)\n        push!(history, :t, time() - time_0)\n        if batch_idx == batchcount && epoch % 5 == 0\n            lpl = log_pseudolikelihood(rbm, train_x)\n            push!(history, :lpl, mean(lpl))\n        end\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Plot of log-pseudolikelihood of trian data during learning.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"fig = Makie.Figure(resolution=(500,300))\nax = Makie.Axis(fig[1,1], xlabel = \"train time\", ylabel=\"pseudolikelihood\")\nMakie.lines!(ax, get(history, :lpl)...)\nfig","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Sample digits from the RBM starting from a random condition.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"nsteps = 3000\nfantasy_F = zeros(nrows*ncols, nsteps)\nfantasy_x = bitrand(28,28,nrows*ncols)\nfantasy_F[:,1] .= RBMs.free_energy(rbm, fantasy_x)\n@time for t in 2:nsteps\n    fantasy_x .= RBMs.sample_v_from_v(rbm, fantasy_x)\n    fantasy_F[:,t] .= RBMs.free_energy(rbm, fantasy_x)\nend\nnothing #hide","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Check equilibration of sampling","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"fig = Makie.Figure(resolution=(400,300))\nax = Makie.Axis(fig[1,1], xlabel=\"sampling time\", ylabel=\"free energy\")\nfantasy_F_Œº = vec(mean(fantasy_F; dims=1))\nfantasy_F_œÉ = vec(std(fantasy_F; dims=1))\nMakie.band!(ax, 1:nsteps, fantasy_F_Œº - fantasy_F_œÉ/2, fantasy_F_Œº + fantasy_F_œÉ/2)\nMakie.lines!(ax, 1:nsteps, fantasy_F_Œº)\nfig","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"Plot the sampled digits.","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"fig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid(reshape(fantasy_x, 28, 28, ncols, nrows)), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"","category":"page"},{"location":"literate/center/","page":"No centering","title":"No centering","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/performance/float32.jl\"","category":"page"},{"location":"literate/performance/float32/#Float32-vs-Float64","page":"Float32 vs. Float64","title":"Float32 vs Float64","text":"","category":"section"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Compare training performance using Float32 vs. Float64.","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"import MKL\nimport MLDatasets\nimport Makie\nimport CairoMakie\nimport RestrictedBoltzmannMachines as RBMs\nusing RestrictedBoltzmannMachines: cd!\nusing ValueHistories: MVHistory","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Using Float32","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float32}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nrbm = RBMs.BinaryRBM(Float32, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory32 = MVHistory()\ntime_0 = time()\n@time RBMs.cd!(\n    rbm, train_x; epochs=100, batchsize=128, steps=1,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history32, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Using Float64","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float64}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nrbm = RBMs.BinaryRBM(Float64, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory64 = MVHistory()\ntime_0 = time()\n@time RBMs.cd!(\n    rbm, train_x; epochs=100, batchsize=128, steps=1,\n    callback = function(@nospecialize(args...); @nospecialize(kw...))\n        push!(history64, :t, time() - time_0)\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Compare","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"epoch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history32, :t)..., label=\"32\")\nMakie.lines!(ax, get(history64, :t)..., label=\"64\")\nMakie.ylims!(ax, low=0)\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"","category":"page"},{"location":"literate/performance/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/ReLU.jl\"","category":"page"},{"location":"literate/layers/ReLU/#ReLU-layer","page":"ReLU","title":"ReLU layer","text":"","category":"section"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"In this example we look at what the ReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"First load some packages.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Now initialize our ReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Œ∏s = [0; 10]\nŒ≥s = [5; 10]\nlayer = RBMs.ReLU([Œ∏ for Œ∏ in Œ∏s, Œ≥ in Œ≥s], [Œ≥ for Œ∏ in Œ∏s, Œ≥ in Œ≥s])\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"fig = Figure(resolution=(700,500))\nax = Axis(fig[1,1])\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1, 1, 100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iŒ∏, Œ∏) in enumerate(Œ∏s), (iŒ≥, Œ≥) in enumerate(Œ≥s)\n    hist!(ax, data[iŒ∏, iŒ≥, :], normalization=:pdf, label=\"Œ∏=$Œ∏, Œ≥=$Œ≥\")\n    lines!(xs[iŒ∏, iŒ≥, :], ps[iŒ∏, iŒ≥, :], linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/MNIST.jl\"","category":"page"},{"location":"literate/MNIST/#MNIST","page":"MNIST","title":"MNIST","text":"","category":"section"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"We begin by importing the required packages. We load MNIST via the MLDatasets.jl package.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"import Makie\nimport CairoMakie\nimport MLDatasets\nimport Flux\nimport RestrictedBoltzmannMachines as RBMs\nusing Statistics: mean, std, var\nusing Random: bitrand\nusing ValueHistories: MVHistory\nusing RestrictedBoltzmannMachines: visible, BinaryRBM, sample_from_inputs, minibatch_count\nusing RestrictedBoltzmannMachines: initialize!, log_pseudolikelihood, pcd!\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Useful function to plot grids of MNIST digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"\"\"\"\n    imggrid(A)\n\nGiven a four dimensional tensor `A` of size `(width, height, ncols, nrows)`\ncontaining `width x height` images in a grid of `nrows x ncols`, this returns\na matrix of size `(width * ncols, height * nrows)`, that can be plotted in a heatmap\nto display all images.\n\"\"\"\nimggrid(A::AbstractArray{<:Any,4}) =\n    reshape(permutedims(A, (1,3,2,4)), size(A,1)*size(A,3), size(A,2)*size(A,4))","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Load the MNIST dataset. We will train an RBM with binary (0,1) visible and hidden units. Therefore we binarize the data. In addition, we consider only one kind of digit so that training is faster.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 0] .‚â• 0.5)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Let's visualize some random digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"nrows, ncols = 10, 15\nfig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nidx = rand(1:size(train_x,3), nrows * ncols) # random indices of digits\ndigits = reshape(train_x[:,:,idx], 28, 28, ncols, nrows)\nMakie.image!(ax, imggrid(digits), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initialize an RBM with 400 hidden units.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"rbm = BinaryRBM(Float, (28,28), 400)\ninitialize!(rbm, train_x) # match single-site statistics\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initially, the RBM assigns a poor pseudolikelihood to the data.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"println(\"log(PL) = \", mean(@time log_pseudolikelihood(rbm, train_x)))","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"(Incidentally, note how long it takes to evaluate the pseudolikelihood on the full dataset.)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now we train the RBM on the data. This returns a MVHistory collecting some info during training.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"batchsize = 256\nbatchcount = minibatch_count(train_x; batchsize)\nepochs = 500\nhistory = MVHistory()\n@time pcd!(\n    rbm, train_x; epochs, batchsize,\n    callback = function(; rbm, epoch, batch_idx, _...)\n        if batch_idx == batchcount && epoch % 5 == 0\n            push!(history, :lpl, mean(log_pseudolikelihood(rbm, train_x)))\n        end\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"After training, the pseudolikelihood score of the data improves significantly. Plot of log-pseudolikelihood of trian data during learning.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Makie.Figure(resolution=(500,300))\nax = Makie.Axis(fig[1,1], xlabel = \"train time\", ylabel=\"pseudolikelihood\")\nMakie.lines!(ax, get(history, :lpl)...)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Sample digits from the RBM starting from a random condition.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"nsteps = 3000\nfantasy_F = zeros(nrows*ncols, nsteps)\nfantasy_x = bitrand(28,28,nrows*ncols)\nfantasy_F[:,1] .= RBMs.free_energy(rbm, fantasy_x)\n@time for t in 2:nsteps\n    fantasy_x .= RBMs.sample_v_from_v(rbm, fantasy_x)\n    fantasy_F[:,t] .= RBMs.free_energy(rbm, fantasy_x)\nend\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Check equilibration of sampling","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Makie.Figure(resolution=(400,300))\nax = Makie.Axis(fig[1,1], xlabel=\"sampling time\", ylabel=\"free energy\")\nfantasy_F_Œº = vec(mean(fantasy_F; dims=1))\nfantasy_F_œÉ = vec(std(fantasy_F; dims=1))\nMakie.band!(ax, 1:nsteps, fantasy_F_Œº - fantasy_F_œÉ/2, fantasy_F_Œº + fantasy_F_œÉ/2)\nMakie.lines!(ax, 1:nsteps, fantasy_F_Œº)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Plot the sampled digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid(reshape(fantasy_x, 28, 28, ncols, nrows)), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [RBMs]","category":"page"},{"location":"reference/#RestrictedBoltzmannMachines.Binary","page":"Reference","title":"RestrictedBoltzmannMachines.Binary","text":"Binary(Œ∏)\n\nBinary layer, with external fields Œ∏.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Gaussian","page":"Reference","title":"RestrictedBoltzmannMachines.Gaussian","text":"Gaussian(Œ∏, Œ≥)\n\nGaussian layer, with location parameters Œ∏ and scale parameters Œ≥.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Potts","page":"Reference","title":"RestrictedBoltzmannMachines.Potts","text":"Potts(Œ∏)\n\nPotts layer, with external fields Œ∏. Encodes categorical variables as one-hot vectors. The number of classes is the size of the first dimension.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.RBM","page":"Reference","title":"RestrictedBoltzmannMachines.RBM","text":"RBM{V,H,W}\n\nRBM, with visible layer of type V, hidden layer of type H, and weights of type W.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.ReLU","page":"Reference","title":"RestrictedBoltzmannMachines.ReLU","text":"ReLU(Œ∏, Œ≥)\n\nReLU layer, with location parameters Œ∏ and scale parameters Œ≥.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Spin","page":"Reference","title":"RestrictedBoltzmannMachines.Spin","text":"Spin(Œ∏)\n\nSpin layer, with external fields Œ∏. The energy of a layer with units s_i is given by:\n\nE = -sum_i theta_i s_i\n\nwhere each spin s_i takes values pm 1.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.BinaryRBM-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.BinaryRBM","text":"BinaryRBM(a, b, w)\nBinaryRBM(N, M)\n\nConstruct an RBM with binary visible and hidden units, which has an energy function:\n\nE(v h) = -av - bh - vwh\n\nEquivalent to RBM(Binary(a), Binary(b), w).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.HopfieldRBM-NTuple{4, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.HopfieldRBM","text":"HopfieldRBM(g, Œ∏, Œ≥, w)\nHopfieldRBM(g, w)\n\nConstruct an RBM with spin visible units and Gaussian hidden units. If not given, Œ∏ = 0 and Œ≥ = 1 by default.\n\nE(v h) = -gv - Œ∏h + sum_mu fracŒ≥_mu2 h_mu^2 - vwh\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.ais-Tuple{RestrictedBoltzmannMachines.RBM, RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractVector}","page":"Reference","title":"RestrictedBoltzmannMachines.ais","text":"ais(rbm0, rbm1, v0, Œ≤s)\n\nProvided v0 is an unbiased sample from rbm0, returns F such that mean(exp.(F)) is an unbiased estimator of Z1/Z0, the ratio of partition functions of rbm1 and rbm0.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.aise-Tuple{RestrictedBoltzmannMachines.RBM, AbstractVector{<:Real}}","page":"Reference","title":"RestrictedBoltzmannMachines.aise","text":"aise(rbm, [Œ≤s]; [nbetas], init=rbm.visible, nsamples=1)\n\nAIS estimator of the log-partition function of rbm. It is recommended to fit init to the single-site statistics of rbm (or the data).\n\n!!! tip Use large nbetas     For more accurate estimates, use larger nbetas. It is usually better to have     large nbetas and small nsamples, rather than large nsamples and small nbetas.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.anneal-Tuple{RestrictedBoltzmannMachines.RBM, RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.anneal","text":"anneal(rbm0, rbm1; Œ≤)\n\nReturns an RBM that interpolates between rbm0 and rbm1. Denoting by E0(v, h) and E1(v, h) the energies assigned by rbm0 and rbm1, respectively, the returned RBM assigns energies given by:\n\nE(v,h) = (1 - Œ≤) * E0(v) + Œ≤ * E1(v, h)\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batch_size-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batch_size","text":"batch_size(layer, x)\n\nBatch sizes of x, with respect to layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batch_size-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batch_size","text":"batch_size(rbm, v, h)\n\nReturns the batch size if energy(rbm, v, h) were computed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchcov-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchcov","text":"batchcov(layer, x; wts = nothing, [mean])\n\nCovariance of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchdims-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchdims","text":"batchdims(layer, x)\n\nIndices of batch dimensions in x, with respect to layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchmean-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchmean","text":"batchmean(layer, x; wts = nothing)\n\nMean of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchstd-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchstd","text":"batchstd(layer, x; wts = nothing, [mean])\n\nStandard deviation of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchvar-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchvar","text":"batchvar(layer, x; wts = nothing, [mean])\n\nVariance of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_invert-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_invert","text":"block_matrix_invert(A, B, C, D)\n\nInversion of a block matrix, using the formula:\n\nbeginbmatrix\n    mathbfA  mathbfB \n    mathbfC  mathbfD\nendbmatrix^-1\n=\nbeginbmatrix\n    left(mathbfA - mathbfB mathbfD^-1 mathbfCright)^-1  mathbf0 \n    mathbf0  left(mathbfD - mathbfC mathbfA^-1 mathbfBright)^-1\nendbmatrix\nbeginbmatrix\n    mathbfI  -mathbfB mathbfD^-1 \n    -mathbfC mathbfA^-1  mathbfI\nendbmatrix\n\nAssumes that A and D are square and invertible.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_logdet-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_logdet","text":"block_matrix_logdet(A, B, C, D)\n\nLog-determinant of a block matrix using the determinant lemma.\n\ndetleft(\n    beginbmatrix\n        mathbfA  mathbfB \n        mathbfC  mathbfD\n    endbmatrix\nright)\n= det(A) det(D - CA^-1B)\n= det(D) det(A - BD^-1C)\n\nHere we assume that A and D are invertible, and moreover are easy to invert (for example, if they are diagonal). We use this to chose one or the other of the two formulas above.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.broadlike-Tuple{Any, Vararg{Any}}","page":"Reference","title":"RestrictedBoltzmannMachines.broadlike","text":"broadlike(A, B...)\n\nBroadcasts A into the size of A .+ B .+ ... (without actually doing a sum).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_rand-Tuple{AbstractVector}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_rand","text":"categorical_rand(ps)\n\nRandomly draw i with probability ps[i]. You must ensure that ps defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample","text":"categorical_sample(P)\n\nGiven a probability array P of size (q, *), returns an array C of size (*), such that C[i] ‚àà 1:q is a random sample from the categorical distribution P[:,i]. You must ensure that P defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits","text":"categorical_sample_from_logits(logits)\n\nGiven a logits array logits of size (q, *) (where q is the number of classes), returns an array X of size (*), such that X[i] is a categorical random sample from the distribution with logits logits[:,i].\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel","text":"categorical_sample_from_logits_gumbel(logits)\n\nLike categoricalsamplefrom_logits, but using the Gumbel trick.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.cd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.cd!","text":"cd!(rbm, data)\n\nTrains the RBM on data using contrastive divergence.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.cdad!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.cdad!","text":"cdad!(rbm, data)\n\nTrains the RBM on data using contrastive divergence. Computes gradients with Zygote.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.center_gradient-Tuple{RestrictedBoltzmannMachines.RBM, NamedTuple, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.center_gradient","text":"center_gradient(rbm, ‚àÇ, Œªv, Œªh)\n\nGiven the gradient ‚àÇ of rbm, returns the gradient of the equivalent centered RBM with offsets Œªv and Œªh.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.cold_metropolis-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.cold_metropolis","text":"cold_metropolis(rbm, v; steps = 1)\n\nSamples the rbm at zero temperature, starting from configuration v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.collect_states-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}}","page":"Reference","title":"RestrictedBoltzmannMachines.collect_states","text":"collect_states(layer)\n\nReturns an array of all states of layer. Only defined for discrete layers.\n\nwarning: Warning\nUse only for small layers. For large layers, the exponential number of states will not fit in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.colors-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Spin}}","page":"Reference","title":"RestrictedBoltzmannMachines.colors","text":"colors(layer)\n\nNumber of possible states of units in discrete layers.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.contrastive_divergence-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.contrastive_divergence","text":"contrastive_divergence(rbm, vd, vm; wd = 1, wm = 1)\n\nContrastive divergence loss. vd is a data sample, and vm are samples from the model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.default_optimizer-Tuple{Int64, Int64, Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.default_optimizer","text":"default_optimizer(nsamples, batchsize, epochs; decay_after, decay_final, clip, optim)\n\nSane defaults for optimizer. All keyword arguments are optional and have default settings. Trains with constant learning rate for first decay_after period, then decays learning rate exponentially every epoch, starting after decay_after of training time, until reaching decay_final at the last epoch. Clips gradients by clip.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energies-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energies","text":"energies(layer, x)\n\nEnergies of units in layer (not reduced over layer dimensions).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energy","text":"energy(layer, x)\n\nLayer energy, reduced over layer dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energy","text":"energy(rbm, v, h)\n\nEnergy of the rbm in the configuration (v,h).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.flatten-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.flatten","text":"flatten(layer, x)\n\nReturns a vectorized version of x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.fpcd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.fpcd!","text":"fpcd!(rbm, data)\n\nTrains the RBM on data using Persistent Contrastive divergence, with fast weights. See http://dl.acm.org/citation.cfm?id=1553374.1553506.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.free_energy","page":"Reference","title":"RestrictedBoltzmannMachines.free_energy","text":"free_energy(layer, inputs = 0)\n\nCumulant generating function of layer, reduced over layer dimensions.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.free_energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.free_energy","text":"free_energy(rbm, v)\n\nFree energy of visible configuration (after marginalizing hidden configurations).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.generate_sequences","page":"Reference","title":"RestrictedBoltzmannMachines.generate_sequences","text":"generate_sequences(n, A = 0:1)\n\nRetruns an iterator over all sequences of length n out of the alphabet A.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.gradmult-Tuple{AbstractArray, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.gradmult","text":"gradmult(‚àÇ, Œª)\n\nMultiplies gradients by a scalar Œª.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.gradnorms-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.gradnorms","text":"gradnorms(‚àÇ)\n\nComputes gradient norms.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.initialize!","page":"Reference","title":"RestrictedBoltzmannMachines.initialize!","text":"initialize!(rbm, [data]; œµ = 1e-6)\n\nInitializes the RBM and returns it. If provided, matches average visible unit activities from data.\n\ninitialize!(layer, [data]; œµ = 1e-6)\n\nInitializes a layer and returns it. If provided, matches average unit activities from data.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.initialize_w!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.initialize_w!","text":"initialize_w!(rbm, data; Œª = 0.1)\n\nInitializes rbm.w such that typical inputs to hidden units are Œª.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_h_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_h_from_v","text":"inputs_h_from_v(rbm, v)\n\nInteraction inputs from visible to hidden layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_v_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_v_from_h","text":"inputs_v_from_h(rbm, h)\n\nInteraction inputs from hidden to visible layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.interaction_energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.interaction_energy","text":"interaction_energy(rbm, v, h)\n\nWeight mediated interaction energy.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_likelihood-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_likelihood","text":"log_likelihood(rbm, v)\n\nLog-likelihood of v under rbm, with the partition function compued by extensive enumeration. For discrete layers, this is exponentially slow for large machines.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_partition-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.log_partition","text":"log_partition(rbm)\n\nLog-partition of rbm, computed by extensive enumeration of visible states (except for particular cases such as Gaussian-Gaussian RBM). This is exponentially slow for large machines.\n\nIf your RBM has a smaller hidden layer, mirroring the layers of the rbm first (see mirror).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_partition_zero_weight-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.log_partition_zero_weight","text":"log_partition_zero_weight(rbm)\n\nLog-partition function of a zero-weight version of rbm.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood","text":"log_pseudolikelihood(rbm, v; exact = false)\n\nLog-pseudolikelihood of v. If exact is true, the exact pseudolikelihood is returned. But this is slow if v consists of many samples. Therefore by default exact is false, in which case the result is a stochastic approximation, where a random site is selected for each sample, and its conditional probability is calculated. In average the results with exact = false coincide with the deterministic result, and the estimate is more precise as the number of samples increases.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_exact-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_exact","text":"log_pseudolikelihood_exact(rbm, v)\n\nLog-pseudolikelihood of v. This function computes the exact pseudolikelihood, doing traces over all sites. Note that this can be slow for large number of samples.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_sites-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray{<:CartesianIndex}}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_sites","text":"log_pseudolikelihood_sites(rbm, v, sites)\n\nLog-pseudolikelihood of a site conditioned on the other sites, where sites is an array of site indices (CartesianIndex), one for each sample. Returns an array of log-pseudolikelihood values, for each sample.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_stoch-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_stoch","text":"log_pseudolikelihood_stoch(rbm, v)\n\nLog-pseudolikelihood of v. This function computes an stochastic approximation, by doing a trace over random sites for each sample. For large number of samples, this is in average close to the exact value of the pseudolikelihood.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.logmeanexp-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.logmeanexp","text":"logmeanexp(A; dims=:)\n\nComputes log.(mean(exp.(A); dims)), in a numerically stable way.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.logstdexp-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.logstdexp","text":"logstdexp(A; dims=:)\n\nComputes log.(std(exp.(A); dims)), in a numerically stable way.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.logvarexp-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.logvarexp","text":"logvarexp(A; dims=:)\n\nComputes log.(var(exp.(A); dims)), in a numerically stable way.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mean_h_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mean_h_from_v","text":"mean_h_from_v(rbm, v)\n\nMean unit activation values, conditioned on the other layer, <h | v>.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mean_v_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mean_v_from_h","text":"mean_v_from_h(rbm, v)\n\nMean unit activation values, conditioned on the other layer, <v | h>.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.metropolis!-Tuple{AbstractArray, RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.metropolis!","text":"metropolis!(v, rbm; Œ≤ = 1)\n\nMetropolis-Hastings sampling from rbm at inverse temperature Œ≤. Uses v[:,:,..,:,1] as initial configurations, and writes the Monte-Carlo chains in v[:,:,..,:,2:end].\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.metropolis-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.metropolis","text":"metropolis(rbm, v; Œ≤ = 1, steps = 1)\n\nMetropolis-Hastings sampling from rbm at inverse temperature Œ≤, starting from configuration v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(nobs; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Vararg{Union{Nothing, AbstractArray}}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(data; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(nobs; batchsize, shuffle = true)\n\nPartition nobs into minibatches of length n. If necessary repeats some observations to complete last batches. (Therefore all batches are of the same size n).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Vararg{Union{Nothing, AbstractArray}}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(datas...; batchsize)\n\nSplits the given datas into minibatches. Each minibatch is a tuple where each entry is a minibatch from the corresponding data within datas. All minibatches are of the same size batchsize (if necessary repeating some samples at the last minibatches).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mirror-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.mirror","text":"mirror(rbm)\n\nReturns a new RBM with viible and hidden layers flipped.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mode_h_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mode_h_from_v","text":"mode_h_from_v(rbm, v)\n\nMode unit activations, conditioned on the other layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mode_v_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mode_v_from_h","text":"mode_v_from_h(rbm, h)\n\nMode unit activations, conditioned on the other layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.moving_average-Tuple{AbstractArray, Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.moving_average","text":"moving_average(A, m)\n\nMoving average of A with window size m.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_decode-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_decode","text":"onehot_decode(X)\n\nGiven a onehot encoded array X of N + 1 dimensions, returns the equivalent categorical array of N dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_encode","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_encode","text":"onehot_encode(A, code)\n\nGiven an array A of N dimensions, returns a one-hot encoded BitArray of N + 1 dimensions where single entries of the first dimension are one.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.pcd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.pcd!","text":"pcd!(rbm, data)\n\nTrains the RBM on data using Persistent Contrastive divergence.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.raise-Tuple{RestrictedBoltzmannMachines.RBM, AbstractVector}","page":"Reference","title":"RestrictedBoltzmannMachines.raise","text":"raise(rbm::RBM, Œ≤s; v, init)\n\nReverse AIS estimator of the log-partition function of rbm. While aise tends to understimate the log of the partition function, raise tends to overstimate it. v must be an equilibrated sample from rbm.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randgumbel-Union{Tuple{}, Tuple{Type{T}}, Tuple{T}} where T","page":"Reference","title":"RestrictedBoltzmannMachines.randgumbel","text":"randgumbel(T = Float64)\n\nGenerates a random Gumbel variate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt-Tuple{Random.AbstractRNG, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt","text":"randnt([rng], a)\n\nRandom standard normal lower truncated at a (that is, Z ‚â• a).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt_half-Tuple{Random.AbstractRNG, Real, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt_half","text":"randnt_half([rng], Œº, œÉ)\n\nSamples the normal distribution with mean Œº and standard deviation œÉ truncated to positive values.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.rdm!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.rdm!","text":"rdm!(rbm, data)\n\nTrains the RBM on data using contrastive divergence with randomly initialized chains. See http://arxiv.org/abs/2105.13889.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.reconstruction_error-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.reconstruction_error","text":"reconstruction_error(rbm, v; steps = 1)\n\nStochastic reconstruction error of v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.repeat_size-Union{Tuple{N}, Tuple{Tuple{Vararg{Int64, N}}, Vararg{Int64}}} where N","page":"Reference","title":"RestrictedBoltzmannMachines.repeat_size","text":"repeat_size(sz, r...)\n\nReturns size(repeat(A, r...)), provided size(A) == sz.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.rescale_activations!-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.rescale_activations!","text":"rescale_activations!(layer, Œª::AbstractArray)\n\nFor continuous layers with scale parameters, re-parameterizes such that unit activations are divided by Œª, and returns true. For other layers just returns false.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.rescale_hidden!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.rescale_hidden!","text":"rescale_hidden!(rbm, Œª::AbstractArray)\n\nFor continuous hidden units with a scale parameter, scales parameters such that hidden unit activations are divided by Œª. For other hidden units does nothing. The resulting RBM is equivalent to the original one.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.reshape_maybe-Tuple{Number, Tuple{}}","page":"Reference","title":"RestrictedBoltzmannMachines.reshape_maybe","text":"reshape_maybe(x, shape)\n\nLike reshape(x, shape), except that zero-dimensional outputs are returned as scalars.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_h","text":"sample_h_from_h(rbm, h; steps = 1)\n\nSamples a hidden configuration conditional on another hidden configuration h. Ensures type stability by requiring that the returned array is of the same type as h.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_v","text":"sample_h_from_v(rbm, v)\n\nSamples a hidden configuration conditional on the visible configuration v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_h","text":"sample_v_from_h(rbm, h)\n\nSamples a visible configuration conditional on the hidden configuration h.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_v","text":"sample_v_from_v(rbm, v; steps = 1)\n\nSamples a visible configuration conditional on another visible configuration v. Ensures type stability by requiring that the returned array is of the same type as v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sitedims-Tuple{RestrictedBoltzmannMachines.AbstractLayer}","page":"Reference","title":"RestrictedBoltzmannMachines.sitedims","text":"sitedims(layer)\n\nNumber of dimensions of layer, with special handling of Potts layer, for which the first dimension doesn't count as a site dimension.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sitesize-Tuple{RestrictedBoltzmannMachines.AbstractLayer}","page":"Reference","title":"RestrictedBoltzmannMachines.sitesize","text":"sitesize(layer)\n\nSize of layer, with special handling of Potts layer, for which the first dimension doesn't count as a site dimension.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sqrt1half-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.sqrt1half","text":"sqrt1half(x)\n\nAccurate computation of sqrt(1 + (x/2)^2) + |x|/2.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_exhaustive","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_exhaustive","text":"substitution_matrix_exhaustive(rbm, v)\n\nReturns an q x N x B tensor of free energies F, where q is the number of possible values of each site, B the number of data points, and N the sequence length:\n\n`q, N, B = size(v)\n\nThus F and v have the same size. The entry F[x,i,b] gives the free energy cost of flipping site i to x of v[b] from its original value to x, that is:\n\nF[x,i,b] = free_energy(rbm, v_) - free_energy(rbm, v[b])\n\nwhere v_ is the same as v[b] in all sites but i, where v_ has the value x.\n\nNote that i can be a set of indices.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_sites","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_sites","text":"substitution_matrix_sites(rbm, v, sites)\n\nReturns an q x B matrix of free energies F, where q is the number of possible values of each site, and B the number of data points. The entry F[x,b] equals the free energy cost of flipping site[b] of v[b] to x, that is (schemetically):\n\nF[x, b] = free_energy(rbm, v_) - free_energy(rbm, v)\n\nwhere v = v[b], and v_ is the same as v in all sites except site[b], where v_ has the value x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.suffstats","page":"Reference","title":"RestrictedBoltzmannMachines.suffstats","text":"suffstats(layer, data; [wts])\n\nComputes the sufficient statistics of layer extracted from data.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.tnmean-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnmean","text":"tnmean(a)\n\nMean of the standard normal distribution, truncated to the interval (a, +‚àû).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnmeanvar-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnmeanvar","text":"tnmeanvar(a)\n\nMean and variance of the standard normal distribution truncated to the interval (a, +‚àû). Equivalent to tnmean(a), tnvar(a) but saves some common computations. WARNING: tnvar(a) can fail for very very large values ofa`.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnvar-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnvar","text":"tnvar(a)\n\nVariance of the standard normal distribution, truncated to the interval (a, +‚àû). WARNING: Fails for very very large values of a.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.total_mean_from_inputs-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.total_mean_from_inputs","text":"total_mean_from_inputs(layer, inputs; wts = nothing)\n\nTotal mean of unit activations from inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.total_meanvar_from_inputs-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.total_meanvar_from_inputs","text":"total_meanvar_from_inputs(layer, inputs; wts = nothing)\n\nTotal mean and total variance of unit activations from inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.total_var_from_inputs-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.total_var_from_inputs","text":"total_var_from_inputs(layer, inputs; wts = nothing)\n\nTotal variance of unit activations from inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.training_epochs-Tuple{}","page":"Reference","title":"RestrictedBoltzmannMachines.training_epochs","text":"training_epochs(; nsamples, nupdates, batchsize)\n\nComputes the number of epochs needed to achieve the given number of gradient nupdates, at a given batchsize, for a dataset of size nsamples.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.uncenter_step-Tuple{RestrictedBoltzmannMachines.RBM, NamedTuple, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.uncenter_step","text":"uncenter_step(rbm, ‚àÇ, Œªv, Œªh)\n\nGiven parameter update step ‚àÇ of a centered rbm with offsets Œªv, Œªh, returns the corresponding gradient of the equivalent uncentered RBM.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.update!-Tuple{AbstractArray, AbstractArray, Any}","page":"Reference","title":"RestrictedBoltzmannMachines.update!","text":"update!(‚àÇ, x, optim)\n\nComputes parameter update step according to optim algorithm (e.g. ADAM), and gradient ‚àÇ of parameters x. Overwrites ‚àÇ with update step and returns it. Note that this does not update parameters.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.update!-Tuple{AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.update!","text":"update!(x, ‚àÇ)\n\nUpdates parameters according to steps ‚àÇ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.var_h_from_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.var_h_from_v","text":"var_h_from_v(rbm, v)\n\nVariance of unit activation values, conditioned on the other layer, var(h | v).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.var_v_from_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.var_v_from_h","text":"var_v_from_h(rbm, v)\n\nVariance of unit activation values, conditioned on the other layer, var(v | h).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.wmean-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.wmean","text":"wmean(A; wts = nothing, dims = :)\n\nWeighted mean of A along dimensions dims, weighted by wts.\n\nfracsum_i A_i w_isum_i w_i\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.wsum-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.wsum","text":"wsum(A; wts = nothing, dims = :)\n\nWeighted sum of A along dimensions dims, weighted by wts.\n\nfracsum_i A_i w_i\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.zerosum!-Tuple{NamedTuple, RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.zerosum!","text":"zerosum!(‚àÇ, rbm)\n\nProjects the gradient so that it doesn't modify the zerosum gauge.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.zerosum!-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.zerosum!","text":"zerosum!(rbm)\n\nIn-place zero-sum gauge on rbm.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.zerosum-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.zerosum","text":"zerosum(rbm)\n\nReturns an equivalent rbm in zerosum gauge. Only affects Potts layers. If the rbm doesn't have Potts layers, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.‚àÇenergy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.‚àÇenergy","text":"‚àÇenergy(layer, data; wts = nothing)\n‚àÇenergy(layer, stats)\n\nDerivative of average energy of data with respect to layer parameters. In the second form, stats are the pre-computed sufficient statistics of the layer. See suffstats.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.‚àÇfree_energy","page":"Reference","title":"RestrictedBoltzmannMachines.‚àÇfree_energy","text":"‚àÇfree_energy(layer, inputs = 0; wts = 1)\n\nUnit activation moments, conjugate to layer parameters. These are obtained by differentiating free_energies with respect to the layer parameters. Averages over configurations (weigthed by wts).\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.‚àÇfree_energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.‚àÇfree_energy","text":"‚àÇfree_energy(rbm, v)\n\nGradient of free_energy(rbm, v) with respect to model parameters. If v consists of multiple samples (batches), then an average is taken.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.‚àÇregularize!-Tuple{NamedTuple, RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.‚àÇregularize!","text":"‚àÇregularize!(‚àÇ, rbm; l2_fields = 0, l1_weights = 0, l2_weights = 0, l2l1_weights = 0)\n\nUpdates RBM gradients ‚àÇ, with the regularization gradient.\n\n\n\n\n\n","category":"method"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/lr_decay.jl\"","category":"page"},{"location":"literate/lr_decay/#Learning-rate-decay","page":"Learning rate decay","title":"Learning rate decay","text":"","category":"section"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Effect of decaying the learning rate during training to achieve convergence.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"using Statistics: mean, std, var\nusing Random: bitrand\nusing LinearAlgebra: dot\nusing ValueHistories: MVHistory\nimport Makie\nimport CairoMakie\nimport Flux\nimport MLDatasets\nusing RestrictedBoltzmannMachines: BinaryRBM, initialize!, pcd!, log_pseudolikelihood, minibatch_count\nusing RestrictedBoltzmannMachines: free_energy, sample_v_from_v, mean_h_from_v, default_optimizer","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Load MNIST dataset. We select only 0 digits and binarize pixel intensities.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float64}(train_x[:,:, train_y .== 0] .> 0.5)\nnsamples = size(train_x)[end]\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Some hyper-parameters","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"nh = 100 # number of hidden units\nepochs = 1000\nbatchsize = 128\nbatchcount = minibatch_count(train_x; batchsize)\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Consider first an RBM that we train without decaying the learning rate.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"rbm_nodecay = initialize!(BinaryRBM(Float, (28,28), nh), train_x)\nhistory_nodecay = MVHistory()\n@time pcd!(\n    rbm_nodecay, train_x; epochs, batchsize,\n    optim = default_optimizer(nsamples, batchsize, epochs; decay_after=1),\n    callback = function callback(; rbm, epoch, batch_idx, _...)\n        if batch_idx == batchcount && epoch % 5 == 0\n            push!(history_nodecay, :lpl, mean(log_pseudolikelihood(rbm, train_x)))\n        end\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Now train an RBM with lr decay after half training (this is the default behavior).","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"rbm_decaylr = initialize!(BinaryRBM(Float, (28,28), nh), train_x)\nhistory_decaylr = MVHistory()\n@time pcd!(\n    rbm_decaylr, train_x; epochs, batchsize,\n    callback = function callback(; rbm, epoch, batch_idx, _...)\n        if batch_idx == batchcount && epoch % 5 == 0\n            push!(history_decaylr, :lpl, mean(log_pseudolikelihood(rbm, train_x)))\n        end\n    end\n)\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Compare the results","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(600,400))\nax = Makie.Axis(fig[1,1])\nMakie.lines!(ax, get(history_nodecay, :lpl)..., label=\"normal\")\nMakie.lines!(ax, get(history_decaylr, :lpl)..., label=\"decay\")\nMakie.axislegend(ax, position=:rb)\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Check convergence by computing the moment-matching conditions. First generate MC data from the RBMs.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"nsteps = 1000\nnsamples = 5000\nF_nodecay = zeros(nsamples, nsteps)\nF_decaylr = zeros(nsamples, nsteps)\nsamples_v_nodecay = bitrand(28,28,nsamples)\nsamples_v_decaylr = bitrand(28,28,nsamples)\nF_nodecay[:,1] .= free_energy(rbm_nodecay, samples_v_nodecay)\nF_decaylr[:,1] .= free_energy(rbm_decaylr, samples_v_decaylr)\n@time for step in 2:nsteps\n    samples_v_nodecay .= sample_v_from_v(rbm_nodecay, samples_v_nodecay)\n    samples_v_decaylr .= sample_v_from_v(rbm_decaylr, samples_v_decaylr)\n    F_nodecay[:,step] .= free_energy(rbm_nodecay, samples_v_nodecay)\n    F_decaylr[:,step] .= free_energy(rbm_decaylr, samples_v_decaylr)\nend\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Check equilibration of sampling","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Samples without lr decay","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(400,300))\nax = Makie.Axis(fig[1,1])\nF_nodecay_Œº = vec(mean(F_nodecay; dims=1))\nF_nodecay_œÉ = vec(std(F_nodecay; dims=1))\nMakie.band!(ax, 1:nsteps, F_nodecay_Œº - F_nodecay_œÉ/2, F_nodecay_Œº + F_nodecay_œÉ/2)\nMakie.lines!(ax, 1:nsteps, F_nodecay_Œº, label=\"no decay\")\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Samples with lr decay","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(400,300))\nax = Makie.Axis(fig[1,1])\nF_decaylr_Œº = vec(mean(F_decaylr; dims=1))\nF_decaylr_œÉ = vec(std(F_decaylr; dims=1))\nMakie.band!(ax, 1:nsteps, F_decaylr_Œº - F_decaylr_œÉ/2, F_decaylr_Œº + F_decaylr_œÉ/2)\nMakie.lines!(ax, 1:nsteps, F_decaylr_Œº, label=\"decay lr\")\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Now make the plots. Average digit shapes.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(900, 300))\nax = Makie.Axis(fig[1,1], title=\"data\", yreversed=true)\nMakie.heatmap!(ax, mean(train_x, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nax = Makie.Axis(fig[1,2], title=\"const. lr\", yreversed=true)\nMakie.heatmap!(ax, mean(samples_v_nodecay, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nax = Makie.Axis(fig[1,3], title=\"lr decay\", yreversed=true)\nMakie.heatmap!(ax, mean(samples_v_decaylr, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Moment matching conditions, first row for RBM with constant learning rate, second row for RBM with learning rate decay.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"h_data_nodecay = mean_h_from_v(rbm_nodecay, train_x)\nh_data_decaylr = mean_h_from_v(rbm_decaylr, train_x)\nh_model_nodecay = mean_h_from_v(rbm_nodecay, samples_v_nodecay)\nh_model_decaylr = mean_h_from_v(rbm_decaylr, samples_v_decaylr)\nnothing #hide\n\nfig = Makie.Figure(resolution=(900, 600))\n\nax = Makie.Axis(fig[1,1], xlabel=\"<v>_data\", ylabel=\"<v>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(train_x; dims=3)), vec(mean(samples_v_nodecay; dims=3)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[1,2], xlabel=\"<h>_data\", ylabel=\"<h>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(h_data_nodecay; dims=2)), vec(mean(h_model_nodecay; dims=2)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[1,3], xlabel=\"<vh>_data\", ylabel=\"<vh>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax,\n    vec([dot(train_x[i,j,:], h_data_nodecay[Œº,:]) / size(train_x,3) for i=1:28, j=1:28, Œº=1:nh]),\n    vec([dot(samples_v_nodecay[i,j,:], h_model_nodecay[Œº,:]) / size(samples_v_nodecay,3) for i=1:28, j=1:28, Œº=1:nh])\n)\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,1], xlabel=\"<v>_data\", ylabel=\"<v>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(train_x; dims=3)), vec(mean(samples_v_decaylr; dims=3)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,2], xlabel=\"<h>_data\", ylabel=\"<h>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(h_data_decaylr; dims=2)), vec(mean(h_model_decaylr; dims=2)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,3], xlabel=\"<vh>_data\", ylabel=\"<vh>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax,\n    vec([dot(train_x[i,j,:], h_data_decaylr[Œº,:]) / size(train_x,3) for i=1:28, j=1:28, Œº=1:nh]),\n    vec([dot(samples_v_decaylr[i,j,:], h_model_decaylr[Œº,:]) / size(samples_v_decaylr,3) for i=1:28, j=1:28, Œº=1:nh])\n)\nMakie.abline!(ax, 0, 1; color=:red)\n\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#RestrictedBoltzmannMachines.jl-Documentation","page":"Home","title":"RestrictedBoltzmannMachines.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package to train and simulate Restricted Boltzmann Machines. The package is registered. Install it with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import Pkg\nPkg.add(\"RestrictedBoltzmannMachines\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The source code is hosted on Github.","category":"page"},{"location":"","page":"Home","title":"Home","text":"https://github.com/cossio/RestrictedBoltzmannMachines.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package doesn't export any symbols. It can be imported like this:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import RestrictedBoltzmannMachines as RBMs","category":"page"},{"location":"","page":"Home","title":"Home","text":"to avoid typing a long name everytime.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Most of the functions have a helpful docstring. See Reference section.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See also the Examples listed on the menu on the left side bar to understand how the package works as a whole.","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/ais.jl\"","category":"page"},{"location":"literate/ais/#Annealed-importance-sampling","page":"AIS","title":"Annealed importance sampling","text":"","category":"section"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"We can compute the partition function of the RBM (and hence the log-likelihood) with annealed importance sampling (AIS).","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"import MLDatasets\nimport Makie\nimport CairoMakie\nimport RestrictedBoltzmannMachines as RBMs\nusing Statistics: mean, std, middle\nusing ValueHistories: MVHistory\nusing RestrictedBoltzmannMachines: Binary, BinaryRBM, initialize!, pcd!,\n    aise, raise, logmeanexp, logstdexp, sample_v_from_v","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"Load MNIST (0 digit only).","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .== 0] .> 0.5)\nnothing #hide","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"Train an RBM","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"rbm = BinaryRBM(Float, (28,28), 128)\ninitialize!(rbm, train_x)\n@time pcd!(rbm, train_x; epochs=100, batchsize=128)\nnothing #hide","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"Estimate Z with AIS and reverse AIS.","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"nsamples=100\nndists = [10, 100, 1000, 10000, 100000]\nR_ais = Vector{Float64}[]\nR_rev = Vector{Float64}[]\nfor nbetas in ndists\n    push!(R_ais,\n        @time aise(rbm; nbetas, nsamples, init=initialize!(Binary(zero(rbm.visible.Œ∏)), train_x))\n    )\n    v = train_x[:, :, rand(1:size(train_x, 3), nsamples)]\n    sample_v_from_v(rbm, v; steps=1000) # equilibrate\n    push!(R_rev,\n        @time raise(rbm; v, nbetas, init=initialize!(Binary(zero(rbm.visible.Œ∏)), train_x))\n    )\nend","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"Plots","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"fig = Makie.Figure()\nax = Makie.Axis(\n    fig[1,1], width=700, height=400, xscale=log10, xlabel=\"interpolating distributions\", ylabel=\"log(Z)\"\n)\nMakie.band!(\n    ax, ndists,\n    mean.(R_ais) - std.(R_ais),\n    mean.(R_ais) + std.(R_ais);\n    color=(:blue, 0.25)\n)\nMakie.band!(\n    ax, ndists,\n    mean.(R_rev) - std.(R_rev),\n    mean.(R_rev) + std.(R_rev);\n    color=(:black, 0.25)\n)\nMakie.lines!(ax, ndists, mean.(R_ais); color=:blue, label=\"AIS\")\nMakie.lines!(ax, ndists, mean.(R_rev); color=:black, label=\"reverse AIS\")\nMakie.lines!(ax, ndists, logmeanexp.(R_ais); color=:blue, linestyle=:dash)\nMakie.lines!(ax, ndists, logmeanexp.(R_rev); color=:black, linestyle=:dash)\nMakie.hlines!(ax, middle(mean(R_ais[end]), mean(R_rev[end])), linestyle=:dash, color=:red, label=\"limiting estimate\")\nMakie.xlims!(extrema(ndists)...)\nMakie.axislegend(ax, position=:rb)\nMakie.resize_to_layout!(fig)\nfig","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"","category":"page"},{"location":"literate/ais/","page":"AIS","title":"AIS","text":"This page was generated using Literate.jl.","category":"page"}]
}
