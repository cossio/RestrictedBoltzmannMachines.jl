var documenterSearchIndex = {"docs":
[{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/drelu.jl\"","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"In this example we look at what the dReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"First load some packages.","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"Now initialize our dReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"θps = [-3.0; 3.0]\nθns = [-3.0; 3.0]\nγps = [0.5; 1.0]\nγns = [0.5; 1.0]\nlayer = RBMs.dReLU(\n    [θp for θp in θps, θn in θns, γp in γps, γn in γns],\n    [θn for θp in θps, θn in θns, γp in γps, γn in γns],\n    [γp for θp in θps, θn in θns, γp in γps, γn in γns],\n    [γn for θp in θps, θn in θns, γp in γps, γn in γns]\n)\nnothing #hide","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"fig = Figure(resolution=(1000, 1000))\nfor (iθp, θp) in enumerate(θps), (iθn, θn) in enumerate(θns)\n    ax = Axis(fig[iθp,iθn], title=\"θp=$θp, θn=$θn\", xlabel=\"h\", ylabel=\"P(h)\")\n    for (iγp, γp) in enumerate(γps), (iγn, γn) in enumerate(γns)\n        hist!(ax, data[iθp, iθn, iγp, iγn, :], normalization=:pdf, bins=30)\n        xs = range(extrema(data[iθp, iθn, iγp, iγn, :])..., 100)\n        ps = exp.(-RBMs.drelu_energy.(θp, θn, γp, γn, xs) .- RBMs.drelu_cgf(θp, θn, γp, γn))\n        lines!(ax, xs, ps, label=\"γp=$γp, γn=$γn\", linewidth=2)\n    end\n    if iθp == iθn == 1\n        axislegend(ax)\n    end\nend\nfig","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"","category":"page"},{"location":"literate/drelu/","page":"dReLU layer","title":"dReLU layer","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/MNIST.jl\"","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"We begin by importing the required packages. We load MNIST via the MLDatasets.jl package.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nimport MLDatasets, Flux\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Let's visualize some random digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Figure(resolution=(800, 300))\nfor i in 1:3, j in 1:8\n    ax = Axis(fig[i,j], yreversed=true)\n    hidedecorations!(ax)\n    heatmap!(ax, MLDatasets.MNIST.traintensor(rand(1:60000)))\nend\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now load the full dataset.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntests_x, tests_y = MLDatasets.MNIST.testdata()\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"train_x, tests_x contain the digit images, while train_y, tests_y contain the labels. We will train an RBM with binary (0,1) visible and hidden units. Therefore we binarize the data first. In addition, we restrict our attention to 0,1 digits only, so that training and so on are faster.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"selected_digits = (0, 1)\ntrain_x = train_x[:, :, train_y .∈ Ref(selected_digits)] .≥ 0.5\ntests_x = tests_x[:, :, tests_y .∈ Ref(selected_digits)] .≥ 0.5\ntrain_y = train_y[train_y .∈ Ref(selected_digits)]\ntests_y = tests_y[tests_y .∈ Ref(selected_digits)]\ntrain_nsamples = length(train_y)\ntests_nsamples = length(tests_y)\n(train_nsamples, tests_nsamples)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"The above train_x and tests_x are BitArrays. Though convenient in terms of memory space, these are very slow in linear algebra. Since we frequently multiply data configurations times the weights of our RBM, we want to speed this up. So we convert to floats, which have much faster matrix multiplies thanks to BLAS. We will use Float32 here. To hit BLAS, this must be consistent with the types we use in the parameters of the RBM below.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Float = Float32\ntrain_x = Float.(train_x)\ntests_x = Float.(tests_x)\ntrain_y = Float.(train_y)\ntests_y = Float.(tests_y)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Plot some examples of the binarized data.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Figure(resolution=(800, 300))\nfor i in 1:3, j in 1:8\n    ax = Axis(fig[i,j], yreversed=true)\n    hidedecorations!(ax)\n    heatmap!(ax, train_x[:,:, rand(1:train_nsamples)])\nend\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initialize an RBM with 100 hidden units. It is recommended to initialize the weights as random normals with zero mean and variance = 1/(number of visible units). See Glorot & Bengio 2010.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Notice how we pass the Float type, to set the parameter type of the layers and weights in the RBM.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"rbm = RBMs.RBM(RBMs.Binary(Float,28,28), RBMs.Binary(Float,200), randn(Float,28,28,200)/28)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initially, the RBM assigns a poor pseudolikelihood to the data.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, train_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, tests_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Incidentally, let us see how long it takes to evaluate the pseudolikelihood on the full dataset.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"@elapsed RBMs.log_pseudolikelihood(rbm, train_x) # pre-compiled by the calls above","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"This is the cost you pay when training by tracking the pseudolikelihood. The pseudolikelihood is computed on the full dataset every epoch. So if this time is too high compared to the computational time of training on an epoch, we should disable tracking the pseudolikelihood.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now we train the RBM on the data. This returns a MVHistory object containing things like the pseudo-likelihood of the data during training. We print here the time spent in the training as a rough benchmark.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"history = RBMs.train!(\n    rbm, train_x; epochs=100, batchsize=128,\n    optimizer=Flux.ADAMW(0.001f0, (0.9f0, 0.999f0), 1f-4)\n)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"After training, the pseudolikelihood score of the data improves significantly.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, train_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, tests_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Plot of log-pseudolikelihood during learning. Note that this shows the pseudolikelihood of the train data.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"lines(get(history, :lpl)...)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now let's generate some random RBM samples. First, we select random data digits to be initial conditions for the Gibbs sampling:","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fantasy_x_init = train_x[:, :, rand(1:train_nsamples, 3 * 8)]\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Let's plot the selected digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fantasy_x_init_ = reshape(fantasy_x_init, 28, 28, 3, 8)\nfig = Figure(resolution=(800, 300))\nfor i in 1:3, j in 1:8\n    ax = Axis(fig[i,j], yreversed=true)\n    hidedecorations!(ax)\n    heatmap!(ax, fantasy_x_init_[:,:,i,j])\nend\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now we do the Gibbs sampling to generate the RBM digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"@elapsed fantasy_x = RBMs.sample_v_from_v(rbm, fantasy_x_init; steps=10000)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Plot the resulting samples.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fantasy_x_ = reshape(fantasy_x, 28, 28, 3, 8)\nfig = Figure(resolution=(800, 300))\nfor i in 1:3, j in 1:8\n    ax = Axis(fig[i,j], yreversed=true)\n    hidedecorations!(ax)\n    heatmap!(ax, fantasy_x_[:,:,i,j])\nend\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"If we initialize parameters, in particular matching the single-site statistics, the model trains better and faster.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"rbm = RBMs.RBM(\n    RBMs.Binary(Float,28,28),\n    RBMs.Binary(Float,200),\n    randn(Float,28,28,200)/28\n)\nhistory_init = RBMs.train!(\n    rbm, train_x; epochs=100, batchsize=128, initialize=true,\n    optimizer=Flux.ADAMW(0.001f0, (0.9f0, 0.999f0), 1f-4)\n)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Compare the learning curves, with and without initialization.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Figure(resolution=(800, 300))\nax = Axis(fig[1,1])\nlines!(ax, get(history, :lpl)..., label=\"no init.\")\nlines!(ax, get(history_init, :lpl)..., label=\"init.\")\naxislegend(ax)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Notice how the pseudolikelihood curve grows a bit faster than before.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, train_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"RBMs.log_pseudolikelihood(rbm, tests_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Let's look at some samples generated by this RBM.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fantasy_x_init = train_x[:, :, rand(1:train_nsamples, 3 * 8)]\nfantasy_x = RBMs.sample_v_from_v(rbm, fantasy_x_init; steps=10000)\nfantasy_x_ = reshape(fantasy_x, 28, 28, 3, 8)\nfig = Figure(resolution=(800, 300))\nfor i in 1:3, j in 1:8\n    ax = Axis(fig[i,j], yreversed=true)\n    hidedecorations!(ax)\n    heatmap!(ax, fantasy_x_[:,:,i,j])\nend\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/gauss.jl\"","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"In this example we look at what the Gaussian layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"First load some packages.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"Now initialize our Gaussian layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"θs = [-5; 5]\nγs = [1; 2]\nlayer = RBMs.Gaussian([θ for θ in θs, γ in γs], [γ for θ in θs, γ in γs])\nnothing #hide","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"fig = Figure(resolution=(500,500))\nax = Axis(fig[1,1])\nxs = range(minimum(data), maximum(data), 100)\nfor (iθ, θ) in enumerate(θs), (iγ, γ) in enumerate(γs)\n    hist!(ax, data[iθ, iγ, :], normalization=:pdf)\n    ps = exp.(-RBMs.gauss_energy.(θ, γ, xs) .- RBMs.gauss_cgf(θ, γ))\n    lines!(xs, ps, label=\"θ=$θ, γ=$γ\", linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"","category":"page"},{"location":"literate/gauss/","page":"Gaussian layer","title":"Gaussian layer","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#RestrictedBoltzmannMachines.jl-Reference","page":"Reference","title":"RestrictedBoltzmannMachines.jl Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [RBMs]","category":"page"},{"location":"reference/#RestrictedBoltzmannMachines.Binary","page":"Reference","title":"RestrictedBoltzmannMachines.Binary","text":"Binary(θ)\n\nBinary layer, with external fields θ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Gaussian","page":"Reference","title":"RestrictedBoltzmannMachines.Gaussian","text":"Gaussian(θ, γ)\n\nGaussian layer, with location parameters θ and scale parameters γ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Potts","page":"Reference","title":"RestrictedBoltzmannMachines.Potts","text":"Potts(θ)\n\nPotts layer, with external fields θ. Encodes categorical variables as one-hot vectors. The number of classes is the size of the first dimension.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.RBM","page":"Reference","title":"RestrictedBoltzmannMachines.RBM","text":"RBM\n\nRepresents a restricted Boltzmann Machine.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.ReLU","page":"Reference","title":"RestrictedBoltzmannMachines.ReLU","text":"ReLU(θ, γ)\n\nReLU layer, with location parameters θ and scale parameters γ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Spin","page":"Reference","title":"RestrictedBoltzmannMachines.Spin","text":"Spin(θ)\n\nSpin layer, with external fields θ. The energy of a layer with units s_i is given by:\n\nE = -sum_i theta_i s_i\n\nwhere each spin s_i takes values pm 1.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.L1L2-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.L1L2","text":"L1L2(rbm)\n\nL1/L2 squared norm of rbm.weights. Visible unit dimensions are reduced with L1 norm, while hidden unit dimensions are reduced with L2 norm. Note that no square root is taken.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_invert-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_invert","text":"block_matrix_invert(A, B, C, D)\n\nInversion of a block matrix, using the formula:\n\nbeginbmatrix\n    mathbfA  mathbfB \n    mathbfC  mathbfD\nendbmatrix^-1\n=\nbeginbmatrix\n    left(mathbfA - mathbfB mathbfD^-1 mathbfCright)^-1  mathbf0 \n    mathbf0  left(mathbfD - mathbfC mathbfA^-1 mathbfBright)^-1\nendbmatrix\nbeginbmatrix\n    mathbfI  -mathbfB mathbfD^-1 \n    -mathbfC mathbfA^-1  mathbfI\nendbmatrix\n\nAssumes that A and D are square and invertible.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_logdet-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_logdet","text":"block_matrix_logdet(A, B, C, D)\n\nLog-determinant of a block matrix using the determinant lemma.\n\ndetleft(\n    beginbmatrix\n        mathbfA  mathbfB \n        mathbfC  mathbfD\n    endbmatrix\nright)\n= det(A) det(D - CA^-1B)\n= det(D) det(A - BD^-1C)\n\nHere we assume that A and D are invertible, and moreover are easy to invert (for example, if they are diagonal). We use this to chose one or the other of the two formulas above.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_rand-Tuple{AbstractVector}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_rand","text":"categorical_rand(ps)\n\nRandomly draw i with probability ps[i]. You must ensure that ps defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample","text":"categorical_sample(P)\n\nGiven a probability array P of size (q, *), returns an array C of size (*), such that C[i] ∈ 1:q is a random sample from the categorical distribution P[:,i]. You must ensure that P defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits","text":"categorical_sample_from_logits(logits)\n\nGiven a logits array logits of size (q, *) (where q is the number of classes), returns an array X of size (*), such that X[i] is a categorical random sample from the distribution with logits logits[:,i].\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel","text":"categorical_sample_from_logits_gumbel(logits)\n\nLike categoricalsamplefrom_logits, but using the Gumbel trick.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.collect_states-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}}","page":"Reference","title":"RestrictedBoltzmannMachines.collect_states","text":"collect_states(layer)\n\nReturns an array of all states of layer. Only defined for discrete layers.\n\nwarning: Warning\n\n\nUse only for small layers. For large layers, the exponential number of states will not fit in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energy","text":"energy(rbm, v, h)\n\nEnergy of the rbm in the configuration (v,h).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.flip_layers-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.flip_layers","text":"flip_layers(rbm)\n\nReturns a new RBM with viible and hidden layers flipped.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.free_energy","page":"Reference","title":"RestrictedBoltzmannMachines.free_energy","text":"free_energy(rbm, v, β=1)\n\nFree energy of visible configuration (after marginalizing hidden configurations).\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.generate_sequences","page":"Reference","title":"RestrictedBoltzmannMachines.generate_sequences","text":"generate_sequences(n, A = 0:1)\n\nRetruns an iterator over all sequences of length n out of the alphabet A.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.initialize!","page":"Reference","title":"RestrictedBoltzmannMachines.initialize!","text":"initialize!(rbm, [data]; ϵ = 1e-6)\n\nInitializes the RBM parameters. If provided, matches average visible unit activities from data.\n\ninitialize!(layer, [data]; ϵ = 1e-6)\n\nInitializes a layer. If provided, matches average unit activities from data.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_h_to_v-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_h_to_v","text":"inputs_h_to_v(rbm, h)\n\nInteraction inputs from hidden to visible layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_v_to_h-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_v_to_h","text":"inputs_v_to_h(rbm, v)\n\nInteraction inputs from visible to hidden layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.interaction_energy-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.interaction_energy","text":"interaction_energy(rbm, v, h)\n\nWeight mediated interaction energy.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_likelihood","page":"Reference","title":"RestrictedBoltzmannMachines.log_likelihood","text":"log_likelihood(rbm, v, β=1)\n\nLog-likelihood of v under rbm, with the partition function compued by extensive enumeration. For discrete layers, this is exponentially slow for large machines.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.log_partition","page":"Reference","title":"RestrictedBoltzmannMachines.log_partition","text":"log_partition(rbm, β = 1)\n\nLog-partition of the rbm at inverse temperature β, computed by extensive enumeration of visible states (except for particular cases such as Gaussian-Gaussian RBM). This is exponentially slow for large machines.\n\nIf your RBM has a smaller hidden layer, consider using flip_layers.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood","text":"log_pseudolikelihood(rbm, v, β=1; exact=false)\n\nLog-pseudolikelihood of v. If exact is true, the exact pseudolikelihood is returned. But this is slow if v consists of many samples. Therefore by default exact is false, in which case the result is a stochastic approximation, where a random site is selected for each sample, and its conditional probability is calculated. In average the results with exact = false coincide with the deterministic result, and the estimate is more precise as the number of samples increases.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_exact","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_exact","text":"log_pseudolikelihood_exact(rbm, v, β = 1)\n\nLog-pseudolikelihood of v. This function computes the exact pseudolikelihood, doing traces over all sites. Note that this can be slow for large number of samples.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_sites","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_sites","text":"log_pseudolikelihood_sites(rbm, v, sites, β=1)\n\nLog-pseudolikelihood of a site conditioned on the other sites, where sites is an array of site indices (CartesianIndex), one for each sample. Returns an array of log-pseudolikelihood values, for each sample.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_stoch","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_stoch","text":"log_pseudolikelihood_stoch(rbm, v, β=1)\n\nLog-pseudolikelihood of v. This function computes an stochastic approximation, by doing a trace over random sites for each sample. For large number of samples, this is in average close to the exact value of the pseudolikelihood.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.lognormcdf-Tuple{Real, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.lognormcdf","text":"lognormcdf(a, b)\n\nComputes log(normcdf(a, b)), but retaining accuracy.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mean_-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mean_","text":"mean_(A; dims)\n\nTakes the mean of A across dimensions dims and drops them.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mills-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.mills","text":"mills(x::Real)\n\nMills ratio of the standard normal distribution. Defined as (1 - cdf(x)) / pdf(x).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(nobs; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Vararg{AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(data; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(nobs; batchsize, shuffle = true)\n\nPartition nobs into minibatches of length n. If necessary repeats some observations to complete last batches. (Therefore all batches are of the same size n).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Vararg{AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(datas...; batchsize)\n\nSplits the given datas into minibatches. Each minibatch is a tuple where each entry is a minibatch from the corresponding data within datas. All minibatches are of the same size batchsize (if necessary repeating some samples at the last minibatches).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.normalize_weights-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.normalize_weights","text":"normalize_weights(rbm)\n\nRescales weights so that norm(w[:,μ]) = 1 for all μ (making individual weights ~ 1/√N). The resulting RBM shares layer parameters with the original, but weights are a new array.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.normcdf-Tuple{Real, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.normcdf","text":"normcdf(a, b)\n\nProbablity that a ≤ Z ≤ b, where Z is a standard normal samplefrominputs variable. WARNING: Silently returns a negative value if a > b.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.normcdf-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.normcdf","text":"normcdf(x)\n\nProbablity that Z ≤ x, where Z is a standard normal samplefrominputs variable.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.normcdfinv-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.normcdfinv","text":"normcdfinv(x)\n\nInverse of normcdf.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_decode-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_decode","text":"onehot_decode(X)\n\nGiven a onehot encoded array X of N + 1 dimensions, returns the equivalent categorical array of N dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_encode","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_encode","text":"onehot_encode(A, code)\n\nGiven an array A of N dimensions, returns a one-hot encoded BitArray of N + 1 dimensions where single entries of the first dimension are one.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.pgm_reg-Union{Tuple{RestrictedBoltzmannMachines.RBM{V}}, Tuple{V}} where V<:Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}","page":"Reference","title":"RestrictedBoltzmannMachines.pgm_reg","text":"pgm_reg(rbm; λv, λw)\n\nRegularization used on https://github.com/jertubiana/PGM.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randgumbel-Union{Tuple{}, Tuple{Type{T}}, Tuple{T}} where T","page":"Reference","title":"RestrictedBoltzmannMachines.randgumbel","text":"randgumbel(T = Float64)\n\nGenerates a random Gumbel variate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt-Tuple{Random.AbstractRNG, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt","text":"randnt([rng], a)\n\nRandom standard normal lower truncated at a (that is, Z ≥ a).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt_half-Tuple{Random.AbstractRNG, Real, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt_half","text":"randnt_half([rng], μ, σ)\n\nSamples the normal distribution with mean μ and standard deviation σ truncated to positive values.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.reconstruction_error","page":"Reference","title":"RestrictedBoltzmannMachines.reconstruction_error","text":"reconstruction_error(rbm, v, β = 1; steps = 1)\n\nStochastic reconstruction error of v.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sample_from_inputs","page":"Reference","title":"RestrictedBoltzmannMachines.sample_from_inputs","text":"sample_from_inputs(layer, inputs, β = 1)\n\nSamples layer configurations conditioned on inputs.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_h","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_h","text":"sample_h_from_h(rbm, h, β = 1; steps = 1)\n\nSamples a hidden configuration conditional on another hidden configuration h.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_v","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_v","text":"sample_h_from_v(rbm, v, β=1)\n\nSamples a hidden configuration conditional on the visible configuration v.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_h","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_h","text":"sample_v_from_h(rbm, h, β = 1)\n\nSamples a visible configuration conditional on the hidden configuration h.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_v","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_v","text":"sample_v_from_v(rbm, v, β = 1; steps = 1)\n\nSamples a visible configuration conditional on another visible configuration v.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sqrt1half-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.sqrt1half","text":"sqrt1half(x)\n\nAccurate computation of sqrt(1 + (x/2)^2) + |x|/2.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.std_-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.std_","text":"std_(A; dims)\n\nTakes the standard deviation of A across dimensions dims and drops them.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_exhaustive","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_exhaustive","text":"substitution_matrix_exhaustive(rbm, v, β = 1)\n\nReturns an q x N x B tensor of free energies F, where q is the number of possible values of each site, B the number of data points, and N the sequence length:\n\n`q, N, B = size(v)\n\nThus F and v have the same size. The entry F[x,i,b] gives the free energy cost of flipping site i to x of v[b] from its original value to x, that is:\n\nF[x,i,b] = free_energy(rbm, v_, β) - free_energy(rbm, v[b], β)\n\nwhere v_ is the same as v[b] in all sites but i, where v_ has the value x.\n\nNote that i can be a set of indices.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_sites","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_sites","text":"substitution_matrix_sites(rbm, v, sites, β = 1)\n\nReturns an q x B matrix of free energies F, where q is the number of possible values of each site, and B the number of data points. The entry F[x,b] equals the free energy cost of flipping site[b] of v[b] to x, that is (schemetically):\n\nF[x, b] = free_energy(rbm, v_) - free_energy(rbm, v)\n\nwhere v = v[b], and v_ is the same as v in all sites except site[b], where v_ has the value x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.sum_-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sum_","text":"sum_(A; dims)\n\nSums A over dimensions dims and drops them.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnmean-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnmean","text":"tnmean(a)\n\nMean of the standard normal distribution, truncated to the interval (a, +∞).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnstd-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnstd","text":"tnstd(a)\n\nStandard deviation of the standard normal distribution, truncated to the interval (a, +∞).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnvar-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnvar","text":"tnvar(a)\n\nVariance of the standard normal distribution, truncated to the interval (a, +∞). WARNING: Fails for very very large values of a.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.train!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.train!","text":"train!(rbm, data)\n\nTrains the RBM on data.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tuplen-Union{Tuple{Val{N}}, Tuple{N}} where N","page":"Reference","title":"RestrictedBoltzmannMachines.tuplen","text":"tuplen(Val(N))\n\nConstructs the tuple (1, 2, ..., N).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.unwhiten-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.unwhiten","text":"unwhiten(rbm, data)\n\nGiven an RBM trained on whitened data, returns an RBM that can look at original data.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.var_-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.var_","text":"var_(A; dims)\n\nTakes the variance of A across dimensions dims and drops them.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.weighted_mean-Tuple{AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.weighted_mean","text":"weighted_mean(v, w)\n\nMean of v with weights w.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.zerosum!-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.zerosum!","text":"zerosum!(rbm)\n\nIf the rbm has Potts layers (visible or hidden), fixes zerosum gauge on the weights and on the layer fields. Otherwise, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"math/#Mathematical-introduction-to-Restricted-Boltzmann-Machines","page":"Mathematical introduction","title":"Mathematical introduction to Restricted Boltzmann Machines","text":"","category":"section"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"A restricted Boltzmann machine (RBM) with visible units mathbfv = (v_1 ldots v_N) and hidden units mathbfh = (h_1 ldots h_M) has an energy function defined by:","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"E(mathbfv mathbfh) = sum_i mathcalV_i(v_i) + sum_mumathcalU_mu(h_mu) - sum_imu w_imu v_i h_mu","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"where mathcalV_i(v_i) and mathcalU_mu(h_mu) are the unit potentials and w_imu the interaction weights. The probability of a configuration is:","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"P(mathbfv mathbfh) = frac1Zmathrme^-beta E(mathbfvmathbfh)","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"where","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"Z = sum_mathbfv mathbfh mathrme^-beta E(mathbfv mathbfh)","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"is the partition function and beta the inverse temperature. The machine assigns a likelihood:","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"P(mathbfv) = undersetmathbfhsum P (mathbfv mathbfh) =\nfrac1Z mathrme^-beta E_textrmeff(mathbfv)","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"to visible configurations, where E_textrmeff(mathbfv) is the free energy:","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"E_textrmeff(mathbfv) = sum_i mathcalV_i(v_i) - sum_mu\nGamma_mu left(sum_i w_i mu v_i right)","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"and","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"Gamma_mu(I) = frac1beta ln sum_h_mu mathrme^beta(I h_mu - mathcalU_mu(h_mu))","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"are the cumulant generating functions associated to the hidden unit potentials.","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"Note that beta refers to the inverse temperature in the distribution P(mathbfvmathbfh). If instead we want to sample the marginal P(mathbfv) at a different inverse temperature beta_v,  we would have to use the distribution:","category":"page"},{"location":"math/","page":"Mathematical introduction","title":"Mathematical introduction","text":"P_beta_v(mathbfv) = fracmathrme^- beta_v E_textrmeff\n(mathbfv)sum_mathbfv mathrme^-beta_mathrmv E_textrmeff\n(mathbfv)","category":"page"},{"location":"#RestrictedBoltzmannMachines.jl-Documentation","page":"Home","title":"RestrictedBoltzmannMachines.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package to train and simulate Restricted Boltzmann Machines.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package doesn't export any symbols. We recommended to import the package like this:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import RestrictedBoltzmannMachines as RBMs","category":"page"},{"location":"","page":"Home","title":"Home","text":"to avoid typing a long name everytime.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/relu.jl\"","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"In this example we look at what the ReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"First load some packages.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"Now initialize our ReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"θs = [0; 10]\nγs = [5; 10]\nlayer = RBMs.ReLU([θ for θ in θs, γ in γs], [γ for θ in θs, γ in γs])\nnothing #hide","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"data = RBMs.sample_from_inputs(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"fig = Figure(resolution=(500,500))\nax = Axis(fig[1,1])\nxs = range(minimum(data), maximum(data), 100)\nfor (iθ, θ) in enumerate(θs), (iγ, γ) in enumerate(γs)\n    hist!(ax, data[iθ, iγ, :], normalization=:pdf)\n    ps = exp.(-RBMs.relu_energy.(θ, γ, xs) .- RBMs.relu_cgf(θ, γ))\n    lines!(xs, ps, label=\"θ=$θ, γ=$γ\", linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"","category":"page"},{"location":"literate/relu/","page":"ReLU layer","title":"ReLU layer","text":"This page was generated using Literate.jl.","category":"page"}]
}
