var documenterSearchIndex = {"docs":
[{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/lr_decay.jl\"","category":"page"},{"location":"literate/lr_decay/#Learning-rate-decay","page":"Learning rate decay","title":"Learning rate decay","text":"","category":"section"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Effect of decaying the learning rate during training to achieve convergence.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"using Statistics: mean\nusing Random: bitrand\nusing LinearAlgebra: dot\nusing ValueHistories: MVHistory\nimport Makie\nimport CairoMakie\nimport Flux\nimport MLDatasets\nimport RestrictedBoltzmannMachines as RBMs","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Load MNIST dataset. We select only 0 digits and binarize pixel intensities.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float64}(train_x[:,:, train_y .== 0] .> 0.5)\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Consider first an RBM that we train without decaying the learning rate. We will train this machine for 300 epochs.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"rbm_nodecay = RBMs.BinaryRBM(Float, (28,28), 100)\nRBMs.initialize!(rbm_nodecay, train_x)\noptim = Flux.ADAM(0.001)\nbatchsize = 256\nvm = bitrand(28, 28, batchsize) # fantasy chains\nhistory_nodecay = MVHistory()\nfor epoch = 1:300\n    RBMs.pcd!(rbm_nodecay, train_x; vm, history=history_nodecay, batchsize, optim)\n    push!(history_nodecay, :lpl, mean(RBMs.log_pseudolikelihood(rbm_nodecay, train_x)))\nend\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Now train an RBM with 200 normal epochs, followed by 100 epochs where the learning-rate is cut in half every 10 epochs.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"nh = 100\nrbm_decaylr = RBMs.BinaryRBM(Float, (28,28), nh)\nRBMs.initialize!(rbm_decaylr, train_x)\noptim = Flux.ADAM(0.001)\nvm = bitrand(28, 28, batchsize)\nhistory_decaylr = MVHistory()\nfor epoch = 1:200 # first 200 epochs without lr decay\n    RBMs.pcd!(rbm_decaylr, train_x; vm, history=history_decaylr, batchsize, optim)\n    push!(history_decaylr, :lpl, mean(RBMs.log_pseudolikelihood(rbm_decaylr, train_x)))\nend\n@info \"*** decaying learning rate ****\"\nfor iter = 1:10, epoch = 1:10 # further 10 epochs with decaying lr\n    optim.eta = 0.001 / 2^iter\n    RBMs.pcd!(rbm_decaylr, train_x; vm, history=history_decaylr, batchsize, optim)\n    push!(history_decaylr, :lpl, mean(RBMs.log_pseudolikelihood(rbm_decaylr, train_x)))\nend\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Compare the results","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(600,400))\nax = Makie.Axis(fig[1,1])\nMakie.lines!(ax, get(history_nodecay, :lpl)..., label=\"normal\")\nMakie.lines!(ax, get(history_decaylr, :lpl)..., label=\"decay\")\nMakie.axislegend(ax, position=:rb)\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Check convergence by computing the moment-matching conditions. First generate MC data from the RBMs.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"@time samples_v_nodecay = RBMs.sample_v_from_v(rbm_nodecay, bitrand(28,28,5000); steps=1000)\n@time samples_v_decaylr = RBMs.sample_v_from_v(rbm_decaylr, bitrand(28,28,5000); steps=1000)\nnothing #hide","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Now make the plots. Average digit shapes.","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"fig = Makie.Figure(resolution=(900, 300))\nax = Makie.Axis(fig[1,1], title=\"data\")\nMakie.heatmap!(ax, mean(train_x, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nax = Makie.Axis(fig[1,2], title=\"const. lr\")\nMakie.heatmap!(ax, mean(samples_v_nodecay, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nax = Makie.Axis(fig[1,3], title=\"lr decay\")\nMakie.heatmap!(ax, mean(samples_v_decaylr, dims=3)[:,:,1])\nMakie.hidedecorations!(ax)\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"Moment matching conditions, first for RBM with constant learning rate","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"h_data_nodecay = RBMs.mean_h_from_v(rbm_nodecay, train_x)\nh_data_decaylr = RBMs.mean_h_from_v(rbm_decaylr, train_x)\nh_model_nodecay = RBMs.mean_h_from_v(rbm_nodecay, samples_v_nodecay)\nh_model_decaylr = RBMs.mean_h_from_v(rbm_decaylr, samples_v_decaylr)\nnothing #hide\n\nfig = Makie.Figure(resolution=(900, 600))\n\nax = Makie.Axis(fig[1,1], xlabel=\"<v>_data\", ylabel=\"<v>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(train_x; dims=3)), vec(mean(samples_v_nodecay; dims=3)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[1,2], xlabel=\"<h>_data\", ylabel=\"<h>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(h_data_nodecay; dims=2)), vec(mean(h_model_nodecay; dims=2)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[1,3], xlabel=\"<vh>_data\", ylabel=\"<vh>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax,\n    vec([dot(train_x[i,j,:], h_data_nodecay[μ,:]) / size(train_x,3) for i=1:28, j=1:28, μ=1:nh]),\n    vec([dot(samples_v_nodecay[i,j,:], h_model_nodecay[μ,:]) / size(samples_v_nodecay,3) for i=1:28, j=1:28, μ=1:nh])\n)\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,1], xlabel=\"<v>_data\", ylabel=\"<v>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(train_x; dims=3)), vec(mean(samples_v_decaylr; dims=3)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,2], xlabel=\"<h>_data\", ylabel=\"<h>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax, vec(mean(h_data_decaylr; dims=2)), vec(mean(h_model_decaylr; dims=2)))\nMakie.abline!(ax, 0, 1; color=:red)\n\nax = Makie.Axis(fig[2,3], xlabel=\"<vh>_data\", ylabel=\"<vh>_model\", limits=(0,1,0,1))\nMakie.scatter!(ax,\n    vec([dot(train_x[i,j,:], h_data_decaylr[μ,:]) / size(train_x,3) for i=1:28, j=1:28, μ=1:nh]),\n    vec([dot(samples_v_decaylr[i,j,:], h_model_decaylr[μ,:]) / size(samples_v_decaylr,3) for i=1:28, j=1:28, μ=1:nh])\n)\nMakie.abline!(ax, 0, 1; color=:red)\n\nfig","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"","category":"page"},{"location":"literate/lr_decay/","page":"Learning rate decay","title":"Learning rate decay","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/MNIST.jl\"","category":"page"},{"location":"literate/MNIST/#MNIST","page":"MNIST","title":"MNIST","text":"","category":"section"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"We begin by importing the required packages. We load MNIST via the MLDatasets.jl package.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"using Statistics: mean\nusing Random: bitrand\nusing ValueHistories: MVHistory\nimport Makie\nimport CairoMakie\nimport MLDatasets\nimport Flux\nimport RestrictedBoltzmannMachines as RBMs\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Useful function to plot grids of MNIST digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"\"\"\"\n    imggrid(A)\n\nGiven a four dimensional tensor `A` of size `(width, height, ncols, nrows)`\ncontaining `width x height` images in a grid of `nrows x ncols`, this returns\na matrix of size `(width * ncols, height * nrows)`, that can be plotted in a heatmap\nto display all images.\n\"\"\"\nimggrid(A::AbstractArray{<:Any,4}) =\n    reshape(permutedims(A, (1,3,2,4)), size(A,1)*size(A,3), size(A,2)*size(A,4))","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Load the MNIST dataset. We will train an RBM with binary (0,1) visible and hidden units. Therefore we binarize the data. In addition, we consider only 0,1 digits so that training is faster.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .∈ Ref((0,1))] .≥ 0.5)\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Let's visualize some random digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"nrows, ncols = 10, 15\nfig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nidx = rand(1:size(train_x,3), nrows * ncols) # random indices of digits\ndigits = reshape(train_x[:,:,idx], 28, 28, ncols, nrows)\nMakie.image!(ax, imggrid(digits), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initialize an RBM with 400 hidden units.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"rbm = RBMs.BinaryRBM(Float, (28,28), 400)\nRBMs.initialize!(rbm, train_x) # match single-site statistics\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Initially, the RBM assigns a poor pseudolikelihood to the data.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"@time RBMs.log_pseudolikelihood(rbm, train_x) |> mean","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"(Incidentally, note how long it takes to evaluate the pseudolikelihood on the full dataset.)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Now we train the RBM on the data. This returns a MVHistory collecting some info during training.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"batchsize = 256\noptim = Flux.ADAM()\nvm = bitrand(28, 28, batchsize) # fantasy chains\nhistory = MVHistory()\n@time for epoch in 1:500\n    RBMs.pcd!(rbm, train_x; vm, history, batchsize, optim)\n    push!(history, :lpl, mean(RBMs.log_pseudolikelihood(rbm, train_x))) # track pseudolikelihood\nend\nnothing #hide","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"After training, the pseudolikelihood score of the data improves significantly. Plot of log-pseudolikelihood of trian data during learning.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Makie.lines(get(history, :lpl)..., axis = (; xlabel = \"train time\", ylabel=\"pseudolikelihood\"))","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Sample digits from the RBM starting from a random condition.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"@elapsed fantasy_x = RBMs.sample_v_from_v(rbm, bitrand(28,28,nrows*ncols); steps=10000)","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"Plot the sampled digits.","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"fig = Makie.Figure(resolution=(40ncols, 40nrows))\nax = Makie.Axis(fig[1,1], yreversed=true)\nMakie.image!(ax, imggrid(reshape(fantasy_x, 28, 28, ncols, nrows)), colorrange=(1,0))\nMakie.hidedecorations!(ax)\nMakie.hidespines!(ax)\nfig","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"","category":"page"},{"location":"literate/MNIST/","page":"MNIST","title":"MNIST","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/Gaussian.jl\"","category":"page"},{"location":"literate/layers/Gaussian/#Gaussian-layer","page":"Gaussian","title":"Gaussian layer","text":"","category":"section"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"In the following example we look at what the Gaussian layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"First load some packages.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Now initialize our Gaussian layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"θs = [-5; 5]\nγs = [1; 2]\nlayer = RBMs.Gaussian([θ for θ in θs, γ in γs], [γ for θ in θs, γ in γs])\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"data = RBMs.transfer_sample(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"fig = Figure(resolution=(700,500))\nax = Axis(fig[1,1])\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1, 1, 100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iθ, θ) in enumerate(θs), (iγ, γ) in enumerate(γs)\n    hist!(ax, data[iθ, iγ, :], normalization=:pdf, label=\"θ=$θ, γ=$γ\")\n    lines!(xs[iθ, iγ, :], ps[iθ, iγ, :], linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"","category":"page"},{"location":"literate/layers/Gaussian/","page":"Gaussian","title":"Gaussian","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/dReLU.jl\"","category":"page"},{"location":"literate/layers/dReLU/#dReLU-layer","page":"dReLU","title":"dReLU layer","text":"","category":"section"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"In this example we look at what the dReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"First load some packages.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"import RestrictedBoltzmannMachines as RBMs\nimport Makie\nimport CairoMakie\nusing Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Now initialize our dReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"θps = [-3.0; 3.0]\nθns = [-3.0; 3.0]\nγps = [0.5; 1.0]\nγns = [0.5; 1.0]\nlayer = RBMs.dReLU(\n    [θp for θp in θps, θn in θns, γp in γps, γn in γns],\n    [θn for θp in θps, θn in θns, γp in γps, γn in γns],\n    [γp for θp in θps, θn in θns, γp in γps, γn in γns],\n    [γn for θp in θps, θn in θns, γp in γps, γn in γns]\n)\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"data = RBMs.transfer_sample(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"fig = Makie.Figure(resolution=(1000, 700))\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1,1,1,1,100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iθp, θp) in enumerate(θps), (iθn, θn) in enumerate(θns)\n    ax = Makie.Axis(fig[iθp,iθn], title=\"θp=$θp, θn=$θn\", xlabel=\"h\", ylabel=\"P(h)\")\n    for (iγp, γp) in enumerate(γps), (iγn, γn) in enumerate(γns)\n        Makie.hist!(ax, data[iθp, iθn, iγp, iγn, :], normalization=:pdf, bins=30, label=\"γp=$γp, γn=$γn\")\n        Makie.lines!(ax, xs[iθp, iθn, iγp, iγn, :], ps[iθp, iθn, iγp, iγn, :], linewidth=2)\n    end\n    if iθp == iθn == 1\n        Makie.axislegend(ax)\n    end\nend\nfig","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"","category":"page"},{"location":"literate/layers/dReLU/","page":"dReLU","title":"dReLU","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/ad.jl\"","category":"page"},{"location":"literate/ad/#Gradients-with-Zygote","page":"AutoDiff","title":"Gradients with Zygote","text":"","category":"section"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"It is possible to calculate gradients with Zygote. Let's compare performance to explicit gradients.","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"import MKL\nimport MLDatasets\nimport Makie\nimport CairoMakie\nimport RestrictedBoltzmannMachines as RBMs\nnothing #hide","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Setup","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Float = Float32\nepochs = 100\nbatchsize = 128\nnothing #hide","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Load MNIST","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .∈ Ref((0,1))] .≥ 0.5)\nnothing #hide","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Train using explicit gradients","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"rbm_∂s = RBMs.BinaryRBM(Float, (28,28), 128)\nRBMs.initialize!(rbm_∂s, train_x)\nhistory_∂s = RBMs.cd!(rbm_∂s, train_x; epochs, batchsize)\nnothing #hide","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Train using Zygote gradients","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"rbm_ad = RBMs.BinaryRBM(Float, (28,28), 128)\nRBMs.initialize!(rbm_ad, train_x)\nhistory_ad = RBMs.cdad!(rbm_ad, train_x; epochs, batchsize)\nnothing #hide","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"Compare timings","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"epoch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history_∂s, :Δt)..., label=\"manual\")\nMakie.lines!(ax, get(history_ad, :Δt)..., label=\"zygote\")\nMakie.ylims!(ax, low=0)\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"","category":"page"},{"location":"literate/ad/","page":"AutoDiff","title":"AutoDiff","text":"This page was generated using Literate.jl.","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/float32.jl\"","category":"page"},{"location":"literate/float32/#Float32-vs-Float64","page":"Float32 vs. Float64","title":"Float32 vs Float64","text":"","category":"section"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Compare training performance using Float32 vs. Float64.","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"import MKL\nimport MLDatasets\nimport Makie\nimport CairoMakie\nimport RestrictedBoltzmannMachines as RBMs","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Using Float32","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float32}(train_x[:, :, train_y .∈ Ref((0,1))] .≥ 0.5)\nrbm = RBMs.BinaryRBM(Float32, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory32 = RBMs.cd!(rbm, train_x; epochs=100, batchsize=128, steps=1)\nnothing #hide","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Using Float64","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"train_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float64}(train_x[:, :, train_y .∈ Ref((0,1))] .≥ 0.5)\nrbm = RBMs.BinaryRBM(Float64, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory64 = RBMs.cd!(rbm, train_x; epochs=100, batchsize=128, steps=1)\nnothing #hide","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"Compare","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"epoch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history32, :Δt)..., label=\"32\")\nMakie.lines!(ax, get(history64, :Δt)..., label=\"64\")\nMakie.ylims!(ax, low=0)\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"","category":"page"},{"location":"literate/float32/","page":"Float32 vs. Float64","title":"Float32 vs. Float64","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [RBMs]","category":"page"},{"location":"reference/#RestrictedBoltzmannMachines.AbstractRBM","page":"Reference","title":"RestrictedBoltzmannMachines.AbstractRBM","text":"AbstractRBM{V,H,W}\n\nAbstract RBM type, with visible layer of type V, hidden layer of type H, and weights of type W.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Binary","page":"Reference","title":"RestrictedBoltzmannMachines.Binary","text":"Binary(θ)\n\nBinary layer, with external fields θ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Gaussian","page":"Reference","title":"RestrictedBoltzmannMachines.Gaussian","text":"Gaussian(θ, γ)\n\nGaussian layer, with location parameters θ and scale parameters γ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Potts","page":"Reference","title":"RestrictedBoltzmannMachines.Potts","text":"Potts(θ)\n\nPotts layer, with external fields θ. Encodes categorical variables as one-hot vectors. The number of classes is the size of the first dimension.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.ReLU","page":"Reference","title":"RestrictedBoltzmannMachines.ReLU","text":"ReLU(θ, γ)\n\nReLU layer, with location parameters θ and scale parameters γ.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.Spin","page":"Reference","title":"RestrictedBoltzmannMachines.Spin","text":"Spin(θ)\n\nSpin layer, with external fields θ. The energy of a layer with units s_i is given by:\n\nE = -sum_i theta_i s_i\n\nwhere each spin s_i takes values pm 1.\n\n\n\n\n\n","category":"type"},{"location":"reference/#RestrictedBoltzmannMachines.BinaryRBM-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.BinaryRBM","text":"BinaryRBM(a, b, w)\nBinaryRBM(N, M)\n\nConstruct an RBM with binary visible and hidden units, which has an energy function:\n\nE(v h) = -av - bh - vwh\n\nEquivalent to RBM(Binary(a), Binary(b), w).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.HopfieldRBM-NTuple{4, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.HopfieldRBM","text":"HopfieldRBM(g, θ, γ, w)\nHopfieldRBM(g, w)\n\nConstruct an RBM with spin visible units and Gaussian hidden units. If not given, θ = 0 and γ = 1 by default.\n\nE(v h) = -gv - θh + sum_mu fracγ_mu2 h_mu^2 - vwh\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.L1L2-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.L1L2","text":"L1L2(rbm)\n\nL1/L2 squared norm of rbm.w. Visible unit dimensions are reduced with L1 norm, while hidden unit dimensions are reduced with L2 norm. Note that no square root is taken.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batch_size-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batch_size","text":"batch_size(layer, x)\n\nBatch sizes of x, with respect to layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batch_size-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batch_size","text":"batch_size(rbm, v, h)\n\nReturns the batch size if energy(rbm, v, h) were computed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchcov-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchcov","text":"batchcov(layer, x; wts = nothing, [mean])\n\nCovariance of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchdims-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchdims","text":"batchdims(layer, x)\n\nIndices of batch dimensions in x, with respect to layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchmean-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchmean","text":"batchmean(layer, x; wts = nothing)\n\nMean of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchstd-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchstd","text":"batchstd(layer, x; wts = nothing, [mean])\n\nStandard deviation of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.batchvar-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.batchvar","text":"batchvar(layer, x; wts = nothing, [mean])\n\nVariance of x over batch dimensions, weigthed by wts.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_invert-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_invert","text":"block_matrix_invert(A, B, C, D)\n\nInversion of a block matrix, using the formula:\n\nbeginbmatrix\n    mathbfA  mathbfB \n    mathbfC  mathbfD\nendbmatrix^-1\n=\nbeginbmatrix\n    left(mathbfA - mathbfB mathbfD^-1 mathbfCright)^-1  mathbf0 \n    mathbf0  left(mathbfD - mathbfC mathbfA^-1 mathbfBright)^-1\nendbmatrix\nbeginbmatrix\n    mathbfI  -mathbfB mathbfD^-1 \n    -mathbfC mathbfA^-1  mathbfI\nendbmatrix\n\nAssumes that A and D are square and invertible.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.block_matrix_logdet-NTuple{4, AbstractMatrix}","page":"Reference","title":"RestrictedBoltzmannMachines.block_matrix_logdet","text":"block_matrix_logdet(A, B, C, D)\n\nLog-determinant of a block matrix using the determinant lemma.\n\ndetleft(\n    beginbmatrix\n        mathbfA  mathbfB \n        mathbfC  mathbfD\n    endbmatrix\nright)\n= det(A) det(D - CA^-1B)\n= det(D) det(A - BD^-1C)\n\nHere we assume that A and D are invertible, and moreover are easy to invert (for example, if they are diagonal). We use this to chose one or the other of the two formulas above.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.broadlike-Tuple{Any, Vararg{Any}}","page":"Reference","title":"RestrictedBoltzmannMachines.broadlike","text":"broadlike(A, B...)\n\nBroadcasts A into the size of A .+ B .+ ... (without actually doing a sum).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_rand-Tuple{AbstractVector}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_rand","text":"categorical_rand(ps)\n\nRandomly draw i with probability ps[i]. You must ensure that ps defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample","text":"categorical_sample(P)\n\nGiven a probability array P of size (q, *), returns an array C of size (*), such that C[i] ∈ 1:q is a random sample from the categorical distribution P[:,i]. You must ensure that P defines a proper probability distribution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits","text":"categorical_sample_from_logits(logits)\n\nGiven a logits array logits of size (q, *) (where q is the number of classes), returns an array X of size (*), such that X[i] is a categorical random sample from the distribution with logits logits[:,i].\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.categorical_sample_from_logits_gumbel","text":"categorical_sample_from_logits_gumbel(logits)\n\nLike categoricalsamplefrom_logits, but using the Gumbel trick.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.cd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.cd!","text":"cd!(rbm, data)\n\nTrains the RBM on data using contrastive divergence.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.cdad!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.cdad!","text":"cdad!(rbm, data)\n\nTrains the RBM on data using contrastive divergence. Computes gradients with Zygote.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.collect_states-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}}","page":"Reference","title":"RestrictedBoltzmannMachines.collect_states","text":"collect_states(layer)\n\nReturns an array of all states of layer. Only defined for discrete layers.\n\nwarning: Warning\nUse only for small layers. For large layers, the exponential number of states will not fit in memory.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.colors-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Spin}}","page":"Reference","title":"RestrictedBoltzmannMachines.colors","text":"colors(layer)\n\nNumber of possible states of units in discrete layers.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.contrastive_divergence-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.contrastive_divergence","text":"contrastive_divergence(rbm, vd, vm; wd = 1, wm = 1)\n\nContrastive divergence loss. vd is a data sample, and vm are samples from the model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.default_optimizer-Tuple{Int64, Int64, Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.default_optimizer","text":"default_optimizer(nsamples, batchsize, epochs; optim = Flux.ADAM(), decay_after = 0.5)\n\nThe default optimizer decays the learning rate exponentially every epoch, starting after decay_after of training time, with a pre-defined schedule. Based on defaults from https://github.com/jertubiana/PGM.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.effective-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.effective","text":"effective(layer, inputs; β = 1)\n\nReturns an effective layer which behaves as the original with the given inputs and temperature.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energies-Tuple{Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energies","text":"energies(layer, x)\n\nEnergies of units in layer (not reduced over layer dimensions).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energy","text":"energy(layer, x)\n\nLayer energy, reduced over layer dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.energy-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.energy","text":"energy(rbm, v, h)\n\nEnergy of the rbm in the configuration (v,h).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.flatten-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.flatten","text":"flatten(layer, x)\n\nReturns a vectorized version of x.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.fpcd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.fpcd!","text":"fpcd!(rbm, data)\n\nTrains the RBM on data using Persistent Contrastive divergence, with fast weights. See http://dl.acm.org/citation.cfm?id=1553374.1553506.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.free_energies-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.free_energies","text":"free_energies(layer, inputs = 0; β = 1)\n\nCumulant generating function of units in layer (not reduced over layer dimensions).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.free_energy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.free_energy","text":"free_energy(layer, inputs = 0; β = 1)\n\nCumulant generating function of layer, reduced over layer dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.free_energy-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.free_energy","text":"free_energy(rbm, v; β = 1)\n\nFree energy of visible configuration (after marginalizing hidden configurations).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.generate_sequences","page":"Reference","title":"RestrictedBoltzmannMachines.generate_sequences","text":"generate_sequences(n, A = 0:1)\n\nRetruns an iterator over all sequences of length n out of the alphabet A.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.gradnorms-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.gradnorms","text":"gradnorms(∂)\n\nComputes gradient norms.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.initialize!","page":"Reference","title":"RestrictedBoltzmannMachines.initialize!","text":"initialize!(rbm, [data]; ϵ = 1e-6)\n\nInitializes the RBM parameters. If provided, matches average visible unit activities from data.\n\ninitialize!(layer, [data]; ϵ = 1e-6)\n\nInitializes a layer. If provided, matches average unit activities from data.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.initialize_w!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.initialize_w!","text":"initialize_w!(rbm, data; λ = 0.1)\n\nInitializes rbm.w such that typical inputs to hidden units are λ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_h_to_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_h_to_v","text":"inputs_h_to_v(rbm, h)\n\nInteraction inputs from hidden to visible layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.inputs_v_to_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.inputs_v_to_h","text":"inputs_v_to_h(rbm, v)\n\nInteraction inputs from visible to hidden layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.interaction_energy-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.interaction_energy","text":"interaction_energy(rbm, v, h)\n\nWeight mediated interaction energy.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_likelihood-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_likelihood","text":"log_likelihood(rbm, v; β = 1)\n\nLog-likelihood of v under rbm, with the partition function compued by extensive enumeration. For discrete layers, this is exponentially slow for large machines.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_partition-Tuple{RestrictedBoltzmannMachines.AbstractRBM}","page":"Reference","title":"RestrictedBoltzmannMachines.log_partition","text":"log_partition(rbm; β = 1)\n\nLog-partition of the rbm at inverse temperature β, computed by extensive enumeration of visible states (except for particular cases such as Gaussian-Gaussian RBM). This is exponentially slow for large machines.\n\nIf your RBM has a smaller hidden layer, mirroring the layers of the rbm first (see mirror).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood","text":"log_pseudolikelihood(rbm, v; β = 1, exact = false)\n\nLog-pseudolikelihood of v. If exact is true, the exact pseudolikelihood is returned. But this is slow if v consists of many samples. Therefore by default exact is false, in which case the result is a stochastic approximation, where a random site is selected for each sample, and its conditional probability is calculated. In average the results with exact = false coincide with the deterministic result, and the estimate is more precise as the number of samples increases.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_exact-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_exact","text":"log_pseudolikelihood_exact(rbm, v; β = 1)\n\nLog-pseudolikelihood of v. This function computes the exact pseudolikelihood, doing traces over all sites. Note that this can be slow for large number of samples.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_sites-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray, AbstractArray{<:CartesianIndex}}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_sites","text":"log_pseudolikelihood_sites(rbm, v, sites; β = 1)\n\nLog-pseudolikelihood of a site conditioned on the other sites, where sites is an array of site indices (CartesianIndex), one for each sample. Returns an array of log-pseudolikelihood values, for each sample.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.log_pseudolikelihood_stoch-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.log_pseudolikelihood_stoch","text":"log_pseudolikelihood_stoch(rbm, v; β = 1)\n\nLog-pseudolikelihood of v. This function computes an stochastic approximation, by doing a trace over random sites for each sample. For large number of samples, this is in average close to the exact value of the pseudolikelihood.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mean_h_from_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mean_h_from_v","text":"mean_h_from_v(rbm, v; β = 1)\n\nMean unit activation values, conditioned on the other layer, <h | v>.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mean_v_from_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mean_v_from_h","text":"mean_v_from_h(rbm, v; β = 1)\n\nMean unit activation values, conditioned on the other layer, <v | h>.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(nobs; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatch_count-Tuple{Vararg{Union{Nothing, AbstractArray}}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatch_count","text":"minibatch_count(data; batchsize)\n\nNumber of minibatches.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Int64}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(nobs; batchsize, shuffle = true)\n\nPartition nobs into minibatches of length n. If necessary repeats some observations to complete last batches. (Therefore all batches are of the same size n).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.minibatches-Tuple{Vararg{Union{Nothing, AbstractArray}}}","page":"Reference","title":"RestrictedBoltzmannMachines.minibatches","text":"minibatches(datas...; batchsize)\n\nSplits the given datas into minibatches. Each minibatch is a tuple where each entry is a minibatch from the corresponding data within datas. All minibatches are of the same size batchsize (if necessary repeating some samples at the last minibatches).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mirror-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.mirror","text":"mirror(rbm)\n\nReturns a new RBM with viible and hidden layers flipped.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mode_h_from_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mode_h_from_v","text":"mode_h_from_v(rbm, v)\n\nMode unit activations, conditioned on the other layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.mode_v_from_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.mode_v_from_h","text":"mode_v_from_h(rbm, h)\n\nMode unit activations, conditioned on the other layer.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_decode-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_decode","text":"onehot_decode(X)\n\nGiven a onehot encoded array X of N + 1 dimensions, returns the equivalent categorical array of N dimensions.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.onehot_encode","page":"Reference","title":"RestrictedBoltzmannMachines.onehot_encode","text":"onehot_encode(A, code)\n\nGiven an array A of N dimensions, returns a one-hot encoded BitArray of N + 1 dimensions where single entries of the first dimension are one.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.pcd!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.pcd!","text":"pcd!(rbm, data)\n\nTrains the RBM on data using Persistent Contrastive divergence.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.pcd_bnorm!-Tuple{RestrictedBoltzmannMachines.RBM{<:RestrictedBoltzmannMachines.Binary, <:RestrictedBoltzmannMachines.Binary}, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.pcd_bnorm!","text":"pcd_bnorm!(rbm, data)\n\nTrains the RBM on data using Persistent Contrastive divergence, with centered gradients, as done in the PGM repo, https://github.com/jertubiana/PGM.\n\nThis is almost equivalent to centering visible units only (see https://github.com/cossio/CenteredRBMs.jl), but the centering of the hidden unit parameters is done much smoother.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.pgm_reg-Tuple{RestrictedBoltzmannMachines.RBM{<:Union{RestrictedBoltzmannMachines.Binary, RestrictedBoltzmannMachines.Potts, RestrictedBoltzmannMachines.Spin}}}","page":"Reference","title":"RestrictedBoltzmannMachines.pgm_reg","text":"pgm_reg(rbm; λv, λw)\n\nRegularization used on https://github.com/jertubiana/PGM.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randgumbel-Union{Tuple{}, Tuple{Type{T}}, Tuple{T}} where T","page":"Reference","title":"RestrictedBoltzmannMachines.randgumbel","text":"randgumbel(T = Float64)\n\nGenerates a random Gumbel variate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt-Tuple{Random.AbstractRNG, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt","text":"randnt([rng], a)\n\nRandom standard normal lower truncated at a (that is, Z ≥ a).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.randnt_half-Tuple{Random.AbstractRNG, Real, Real}","page":"Reference","title":"RestrictedBoltzmannMachines.randnt_half","text":"randnt_half([rng], μ, σ)\n\nSamples the normal distribution with mean μ and standard deviation σ truncated to positive values.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.rdm!-Tuple{RestrictedBoltzmannMachines.RBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.rdm!","text":"rdm!(rbm, data)\n\nTrains the RBM on data using contrastive divergence with randomly initialized chains. See http://arxiv.org/abs/2105.13889.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.reconstruction_error-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.reconstruction_error","text":"reconstruction_error(rbm, v; β = 1, steps = 1)\n\nStochastic reconstruction error of v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.reshape_maybe-Tuple{Number, Tuple{}}","page":"Reference","title":"RestrictedBoltzmannMachines.reshape_maybe","text":"reshape_maybe(x, shape)\n\nLike reshape(x, shape), except that zero-dimensional outputs are returned as scalars.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_h","text":"sample_h_from_h(rbm, h; β = 1, steps = 1)\n\nSamples a hidden configuration conditional on another hidden configuration h. Ensures type stability by requiring that the returned array is of the same type as h.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_h_from_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_h_from_v","text":"sample_h_from_v(rbm, v; β = 1)\n\nSamples a hidden configuration conditional on the visible configuration v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_h","text":"sample_v_from_h(rbm, h; β = 1)\n\nSamples a visible configuration conditional on the hidden configuration h.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sample_v_from_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.sample_v_from_v","text":"sample_v_from_v(rbm, v; β = 1, steps = 1)\n\nSamples a visible configuration conditional on another visible configuration v. Ensures type stability by requiring that the returned array is of the same type as v.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sitedims-Tuple{RestrictedBoltzmannMachines.AbstractLayer}","page":"Reference","title":"RestrictedBoltzmannMachines.sitedims","text":"sitedims(layer)\n\nNumber of dimensions of layer, with special handling of Potts layer, for which the first dimension doesn't count as a site dimension.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sitesize-Tuple{RestrictedBoltzmannMachines.AbstractLayer}","page":"Reference","title":"RestrictedBoltzmannMachines.sitesize","text":"sitesize(layer)\n\nSize of layer, with special handling of Potts layer, for which the first dimension doesn't count as a site dimension.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.sqrt1half-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.sqrt1half","text":"sqrt1half(x)\n\nAccurate computation of sqrt(1 + (x/2)^2) + |x|/2.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_exhaustive","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_exhaustive","text":"substitution_matrix_exhaustive(rbm, v; β = 1)\n\nReturns an q x N x B tensor of free energies F, where q is the number of possible values of each site, B the number of data points, and N the sequence length:\n\n`q, N, B = size(v)\n\nThus F and v have the same size. The entry F[x,i,b] gives the free energy cost of flipping site i to x of v[b] from its original value to x, that is:\n\nF[x,i,b] = free_energy(rbm, v_) - free_energy(rbm, v[b])\n\nwhere v_ is the same as v[b] in all sites but i, where v_ has the value x.\n\nNote that i can be a set of indices.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.substitution_matrix_sites","page":"Reference","title":"RestrictedBoltzmannMachines.substitution_matrix_sites","text":"substitution_matrix_sites(rbm, v, sites; β = 1)\n\nReturns an q x B matrix of free energies F, where q is the number of possible values of each site, and B the number of data points. The entry F[x,b] equals the free energy cost of flipping site[b] of v[b] to x, that is (schemetically):\n\nF[x, b] = free_energy(rbm, v_) - free_energy(rbm, v)\n\nwhere v = v[b], and v_ is the same as v in all sites except site[b], where v_ has the value x.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.suffstats","page":"Reference","title":"RestrictedBoltzmannMachines.suffstats","text":"suffstats(layer, data; [wts])\n\nComputes the sufficient statistics of layer extracted from data.\n\n\n\n\n\n","category":"function"},{"location":"reference/#RestrictedBoltzmannMachines.tnmean-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnmean","text":"tnmean(a)\n\nMean of the standard normal distribution, truncated to the interval (a, +∞).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.tnvar-Tuple{Real}","page":"Reference","title":"RestrictedBoltzmannMachines.tnvar","text":"tnvar(a)\n\nVariance of the standard normal distribution, truncated to the interval (a, +∞). WARNING: Fails for very very large values of a.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_mean-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_mean","text":"transfer_mean(layer, inputs = 0; β = 1)\n\nMean of unit activations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_mean_abs-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_mean_abs","text":"transfer_mean_abs(layer, inputs = 0; β = 1)\n\nMean of absolute value of unit activations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_mode-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_mode","text":"transfer_mode(layer, inputs = 0)\n\nMode of unit activations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_sample-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_sample","text":"transfer_sample(layer, inputs = 0; β = 1)\n\nSamples layer configurations conditioned on inputs.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_std-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_std","text":"transfer_std(layer, inputs = 0; β = 1)\n\nStandard deviation of unit activations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.transfer_var-Tuple{RestrictedBoltzmannMachines.AbstractLayer, Union{Real, AbstractArray}}","page":"Reference","title":"RestrictedBoltzmannMachines.transfer_var","text":"transfer_var(layer, inputs = 0; β = 1)\n\nVariance of unit activations.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.update!-Tuple{AbstractArray, AbstractArray, Any}","page":"Reference","title":"RestrictedBoltzmannMachines.update!","text":"update!(∂, x, optim)\n\nComputes parameter update step according to optim algorithm (e.g. ADAM), and gradient ∂ of parameters x. Overwrites ∂ with update step and returns it. Note that this does not update parameters.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.update!-Tuple{AbstractArray, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.update!","text":"update!(x, ∂)\n\nUpdates parameters according to steps ∂.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.var_h_from_v-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.var_h_from_v","text":"var_h_from_v(rbm, v; β = 1)\n\nVariance of unit activation values, conditioned on the other layer, var(h | v).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.var_v_from_h-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.var_v_from_h","text":"var_v_from_h(rbm, v; β = 1)\n\nVariance of unit activation values, conditioned on the other layer, var(v | h).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.wmean-Tuple{AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.wmean","text":"wmean(A; wts = nothing, dims = :)\n\nWeighted mean of A along dimensions dims, weighted by wts.\n\nfrac1Nsum_i A_i w_i\n\nNote that the weights are not normalized.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.zerosum!-Tuple{RestrictedBoltzmannMachines.RBM}","page":"Reference","title":"RestrictedBoltzmannMachines.zerosum!","text":"zerosum!(rbm)\n\nIf the rbm has Potts layers (visible or hidden), fixes zerosum gauge on the parameters. Otherwise, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.∂energy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.∂energy","text":"∂energy(layer, data; wts = nothing)\n∂energy(layer, stats)\n\nDerivative of average energy of data with respect to layer parameters. In the second form, stats are the sufficient statistics of the layer. See suffstats.\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.∂free_energy-Tuple{RestrictedBoltzmannMachines.AbstractLayer, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.∂free_energy","text":"∂free_energy(layer, inputs = 0; wts = 1)\n\nUnit activation moments, conjugate to layer parameters. These are obtained by differentiating free_energies with respect to the layer parameters. Averages over configurations (weigthed by wts).\n\n\n\n\n\n","category":"method"},{"location":"reference/#RestrictedBoltzmannMachines.∂free_energy-Tuple{RestrictedBoltzmannMachines.AbstractRBM, AbstractArray}","page":"Reference","title":"RestrictedBoltzmannMachines.∂free_energy","text":"∂free_energy(rbm, v)\n\nGradient of free_energy(rbm, v) with respect to model parameters. If v consists of multiple samples (batches), then an average is taken.\n\n\n\n\n\n","category":"method"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/mkl.jl\"","category":"page"},{"location":"literate/mkl/#MKL-vs.-OpenBLAS","page":"MKL","title":"MKL vs. OpenBLAS","text":"","category":"section"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"With an Intel CPU, MKL is generally faster than OpenBLAS. Let's do a quick comparison.","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"import MLDatasets\nimport Makie\nimport CairoMakie","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Load MNIST","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Float = Float32\ntrain_x, train_y = MLDatasets.MNIST.traindata()\ntrain_x = Array{Float}(train_x[:, :, train_y .∈ Ref((0,1))] .≥ 0.5)\nnothing #hide","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Make  sure we are using OpenBLAS first:","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"using LinearAlgebra\nLinearAlgebra.__init__() # use OpenBLAS\nBLAS.get_config()","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Number of BLAS threads:","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"BLAS.get_num_threads()","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Train RBM using OpenBLAS.","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"import RestrictedBoltzmannMachines as RBMs\nrbm = RBMs.BinaryRBM(Float, (28,28), 128)\nRBMs.initialize!(rbm, train_x)\nhistory_openblas = RBMs.cd!(rbm, train_x; epochs=50, batchsize=128, steps=1)\nnothing #hide","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Now load MKL.","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"using MKL\nMKL.__init__() # don't need this on a fresh Julia session\nBLAS.get_config()","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Number of BLAS threads:","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"BLAS.get_num_threads()","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"Now let's rerun the RBM training.","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"RBMs.initialize!(rbm, train_x)\nhistory_mkl = RBMs.cd!(rbm, train_x; epochs=50, batchsize=128, steps=1)\nnothing #hide","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"The epochs should be somewhat faster with MKL.","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"fig = Makie.Figure(resolution=(600, 400))\nax = Makie.Axis(fig[1,1], xlabel=\"epoch\", ylabel=\"seconds\")\nMakie.lines!(ax, get(history_openblas, :Δt)..., label=\"OpenBLAS\")\nMakie.lines!(ax, get(history_mkl, :Δt)..., label=\"MKL\")\nMakie.ylims!(ax, low=0)\nMakie.axislegend(ax, position=:rt)\nfig","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"","category":"page"},{"location":"literate/mkl/","page":"MKL","title":"MKL","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#RestrictedBoltzmannMachines.jl-Documentation","page":"Home","title":"RestrictedBoltzmannMachines.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package to train and simulate Restricted Boltzmann Machines. The package is registered. Install it with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import Pkg\nPkg.add(\"RestrictedBoltzmannMachines\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The source code is hosted on Github.","category":"page"},{"location":"","page":"Home","title":"Home","text":"https://github.com/cossio/RestrictedBoltzmannMachines.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package doesn't export any symbols. It can be imported like this:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import RestrictedBoltzmannMachines as RBMs","category":"page"},{"location":"","page":"Home","title":"Home","text":"to avoid typing a long name everytime.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Most of the functions have a helpful docstring. See Reference section.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See also the Examples listed on the menu on the left side bar to understand how the package works as a whole.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Training info is printed to the debug logger, and are hidden by default. To enable them, set:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ENV[\"JULIA_DEBUG\"] = \"RestrictedBoltzmannMachines\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"See https://docs.julialang.org/en/v1/stdlib/Logging/ for more sophisticated approaches.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"EditURL = \"https://github.com/cossio/RestrictedBoltzmannMachines.jl/blob/master/docs/src/literate/layers/ReLU.jl\"","category":"page"},{"location":"literate/layers/ReLU/#ReLU-layer","page":"ReLU","title":"ReLU layer","text":"","category":"section"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"In this example we look at what the ReLU layer hidden units look like, for different parameter values.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"First load some packages.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"import RestrictedBoltzmannMachines as RBMs\nusing CairoMakie, Statistics\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Now initialize our ReLU layer, with unit parameters spanning an interesting range.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"θs = [0; 10]\nγs = [5; 10]\nlayer = RBMs.ReLU([θ for θ in θs, γ in γs], [γ for θ in θs, γ in γs])\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Now we sample our layer to collect some data.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"data = RBMs.transfer_sample(layer, zeros(size(layer)..., 10^6))\nnothing #hide","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"Let's plot the resulting histogram of the activations of each unit. We also overlay the analytical PDF.","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"fig = Figure(resolution=(700,500))\nax = Axis(fig[1,1])\nxs = repeat(reshape(range(minimum(data), maximum(data), 100), 1, 1, 100), size(layer)...)\nps = exp.(RBMs.free_energies(layer) .- RBMs.energies(layer, xs))\nfor (iθ, θ) in enumerate(θs), (iγ, γ) in enumerate(γs)\n    hist!(ax, data[iθ, iγ, :], normalization=:pdf, label=\"θ=$θ, γ=$γ\")\n    lines!(xs[iθ, iγ, :], ps[iθ, iγ, :], linewidth=2)\nend\naxislegend(ax)\nfig","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"","category":"page"},{"location":"literate/layers/ReLU/","page":"ReLU","title":"ReLU","text":"This page was generated using Literate.jl.","category":"page"}]
}
